{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-14T01:08:04.629725Z",
     "start_time": "2023-09-14T01:08:04.427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "Thu Sep 14 10:08:03 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 536.99       CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     On  | 00000000:01:00.0 Off |                  N/A |\r\n",
      "|  0%   36C    P8              10W / 220W |    543MiB /  8192MiB |     10%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|  No running processes found                                                           |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 10:08:22.831155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-14 10:08:22.854809: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-09-14 10:08:22.854828: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "tf.config.list_physical_devices('GPU') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-14T01:08:23.412015Z",
     "start_time": "2023-09-14T01:08:21.958443Z"
    }
   },
   "id": "f26c4e550def8b60"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/ralphpark/aiffel'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T19:19:14.507604Z",
     "start_time": "2023-09-13T19:19:14.463230Z"
    }
   },
   "id": "2561122581988068"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. 뉴스 요약봇 만들기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85136d4de5a013ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-1. 들어가며\n",
    "\n",
    "### 학습 내용\n",
    "2. 텍스트 요약(Text Summarization)\n",
    " - 텍스트 요약 방법인 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)에 대해서 알아봅니다.\n",
    "3. 인공 신경망으로 텍스트 요약 훈련시키기\n",
    " - seq2seq 모델에 대한 개요와 구조 그리고 요소들에 대해서 알아봅니다.\n",
    "4. 데이터 준비하기\n",
    " - Kaggle에서 제공하는 아마존 리뷰 데이터셋을 다운받고, 데이터를 확인해 봅니다.\n",
    "5.  ~ 7. 데이터 전처리하기\n",
    " - 불용어 제거, 정규화, 정수인코딩 등의 데이터 전처리 과정을 코드로 구현합니다.\n",
    "8. 모델 설계하기\n",
    " - 인코더와 디코더, 어텐셔을 설계하고 코드로 구현합니다.\n",
    "9. 모델 훈련하기\n",
    " - EarlyStopping에 대해서 알아보고, 이를 적용하여 모델을 학습합니다.\n",
    "10. 인퍼런스 모델 구현하기\n",
    " - 정수 인덱스 행렬로 나온 결과값을 실제 데이터로 복원하는 인퍼런스 모델을 코드로 구현합니다.\n",
    "11. 모델 테스트하기\n",
    " - 모델을 통해 얻은 요약문과 실제 요약문을 비교해 봅니다.\n",
    "12. 추출적 요약 해보기\n",
    " - summa 패키지를 사용하여 추출적 요약(Extractive Summarization)을 해봅니다.\n",
    "\n",
    "### 학습 목표\n",
    "\n",
    "Extractive/Abstractive summarization 이해할 수 있습니다.\n",
    "\n",
    "단어장 크기를 줄이는 다양한 text normalization 적용할 수 있습니다.\n",
    "\n",
    "seq2seq의 성능을 Up시키는 Attention Mechanism 적용할 수 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a76e29339507055"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-2. 텍스트 요약(Text Summarization)이란?\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-1.png)\n",
    "텍스트 요약(Text Summarization)이란 위 그림과 같이 긴 길이의 문서(Document) 원문을 핵심 주제만으로 구성된 짧은 요약(Summary) 문장들로 변환하는 것을 말합니다. 예를 들어 상대적으로 큰 텍스트인 뉴스 기사로 작은 텍스트인 뉴스 제목을 만들어내는 것이 텍스트 요약의 대표적인 예라고 할 수 있어요.\n",
    "\n",
    "이때 중요한 것은 요약 전후에 정보 손실 발생이 최소화되어야 한다는 점입니다. 이것은 정보를 압축하는 과정과 같습니다. 비록 텍스트의 길이가 크게 줄어들었지만, 요약문은 문서 원문이 담고 있는 정보를 최대한 보존하고 있어야 합니다. 이것은 원문의 길이가 길수록 만만치 않은 어려운 작업이 됩니다. 사람이 이 작업을 수행한다 하더라도 긴 문장을 정확하게 읽고 이해한 후, 그 의미를 손상하지 않는 짧은 다른 표현으로 원문을 번역해 내야 하는 것입니다.\n",
    "\n",
    "그렇게 요약 문장을 만들어 내려면 어떤 방법을 사용하면 좋을까요? 여기서 텍스트 요약은 크게 추출적 요약(Extractive Summarization)과 추상적 요약(Abstractive Summarization)의 두 가지 접근으로 나누어볼 수 있습니다.\n",
    "\n",
    "### 추출적 요약(Extractive Summarization)\n",
    "첫 번째 방식인 추출적 요약은 단어 그대로 원문에서 문장들을 추출해서 요약하는 방식이에요. 가령, 10개의 문장으로 구성된 텍스트가 있다면, 그중 핵심적인 문장 3개를 꺼내와서 3개의 문장으로 구성된 요약문을 만드는 식이죠. 그런데 꺼내온 3개의 문장이 원문에서 중요한 문장일 수는 있어도, 3개의 문장의 연결이 자연스럽지 않을 수는 있거든요. 결과로 나온 문장들 간의 호응이 자연스럽지 않을 수 있다는 것이죠. 딥 러닝보다는 주로 전통적인 머신 러닝 방식에 속하는 텍스트 랭크(TextRank)와 같은 알고리즘을 사용해서 이 방법을 사용한다고 해요.\n",
    "\n",
    "이런 방식을 이미 서비스에 도입해서 활용하고 있는 사례가 있다는 것, 알고 계셨나요? 가장 대표적인 것이 네이버 뉴스 서비스에 있는 요약봇 기능입니다.\n",
    "\n",
    "네이버 뉴스에 접속해서 아무 뉴스 기사나 클릭해 봅시다. 제목 우하단의 요약봇 버튼을 다시 클릭해 보세요. 기사 원문을 단 3줄로 요약한 글을 보실 수 있습니다. 어떤가요? 가끔은 세 문장 간 연결이 조금 매끄럽지 않게 느껴질 때도 있지만 꽤 그럴듯한 요약문으로 보입니다. 위에서 소개한 TextRank 알고리즘을 통해 해당 기사를 가장 잘 대표하는 단어들로 이루어진 핵심문장을 아주 효과적으로 찾아내기 때문입니다. 잘 찾아보면 요약문에 사용된 문장 3개가 원문에 그대로 있다는 것을 알 수 있을 것입니다.\n",
    "\n",
    "### 추상적 요약(Abstractive Summarization)\n",
    "두 번째 방식인 추상적 요약은 추출적 요약보다 좀 더 흥미로운 접근을 사용합니다. 원문으로부터 내용이 요약된 새로운 문장을 생성해내는 것이죠. 여기서 새로운 문장이라는 것은 결과로 나온 문장이 원문에 원래 없던 문장일 수도 있다는 것을 의미합니다. 자연어 처리 분야 중 자연어 생성(Natural Language Generation, NLG)의 영역인 셈이죠. 반면, 추출적 요약은 원문을 구성하는 문장 중 어느 것이 요약문에 들어갈 핵심문장인지를 판별한다는 점에서 문장 분류(Text Classification) 문제로 볼 수 있을 것입니다.\n",
    "\n",
    "자연어 생성하면 혹시 떠오르는 신경망이 있나요? 가장 기본적인 신경망 중 하나인데... 맞아요! RNN으로 이 문제를 풀 수 있겠군요! 그렇다면, RNN으로 추상적 요약 방식을 구현한다고 하면 문제가 전혀 없을까요?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8566f3b741849eff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. RNN은 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 현재에 전달하기 어렵다는 문제가 있습니다. 이 문제를 해결하기 위해 LSTM과 GRU가 등장했고, 이 둘도 부족해서 어텐션(Attention) 메커니즘이 등장했지요. 이 문제의 이름은 무엇인가요?\n",
    "\n",
    "장기 의존성(long term dependencies) 문제\n",
    "\n",
    "장기 의존성 문제는 순환 신경망(RNN)에서 발생하는 문제로, 학습 데이터의 길이가 길어질수록 먼 과거의 정보를 현재에 전달하기 어렵다는 것을 의미합니다. RNN은 시간적인 의존성을 모델링하는 데 강점이 있지만, 그래디언트 소실 또는 그래디언트 폭주와 같은 문제로 인해 장기적인 의존성을 적절히 학습하기 어려울 수 있습니다.\n",
    "\n",
    "장기 의존성 문제를 해결하기 위해 등장한 LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit)은 RNN의 변형 구조로, 기본 RNN보다 더 긴 시간 간격에서의 정보를 보다 효과적으로 전달할 수 있도록 설계되었습니다. LSTM과 GRU는 게이트 메커니즘이라는 구조를 도입하여 그래디언트 흐름을 제어하고 장기적인 의존성을 캡처할 수 있는 기능을 제공합니다.\n",
    "\n",
    "그러나 LSTM과 GRU도 모든 상황에서 완벽한 해결책은 아니며, 특히 입력 시퀀스가 매우 긴 경우에도 여전히 한계가 있습니다. 이에 따라 어텐션 메커니즘이 등장하였습니다. 어텐션은 입력 시퀀스의 다양한 위치에 주목(attention)하여 중요한 정보를 집중(concentrate)시키고, 필요한 정보에 가중치를 부여하여 모델이 장기 의존성을 보다 효과적으로 학습할 수 있게 돕습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3963af6d49ae1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "그저 RNN을 이용해 Language Generation을 한다고 해서 긴 문장을 읽고 나서 요약문을 뚝딱 만들어내긴 어렵겠죠. 어떤 방법을 사용할 지 고민을 할 때, 잘 하는 친구들은 어떻게 하는지 찾아보는 것은 꽤 많은 도움이 돼요. ML 분야의 선구자라고 할 수 있는 기업 '구글(Google)'은 자신들의 서비스에 어떤 방식으로 텍스트 요약을 시도했었을까요? 2016년의 아래 기사에 따르면, 구글은 뉴스 기사 내용으로부터 자동으로 뉴스 제목을 뽑아내는 텍스트 요약 모델을 구현했었다고 합니다. 어떻게 구현했는지, 잠깐 읽어볼까요?\n",
    "\n",
    "\n",
    "구글 인공지능 \"뉴스 제목도 잘 뽑네\"\n",
    "\n",
    "https://zdnet.co.kr/view/?no=20160905114833&from=Mobile"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14ef67f1ac099dd2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 구글에서 텍스트 요약을 위해 시도했던 접근법 중에, 텍스트마이닝 분야의 '역문서빈도(IDF)같은' 지표를 활용해 문서 안에서 중요해 보이는 부분을 추출하고 그걸 요약문에 담는 방식을 썼을 때의 문제점은 무엇이었나요?\n",
    "\n",
    "원문에서 발췌하는 방식(Extractive summarization)의 요약 기법은 어색하거나 문법적으로 이상한 결과물을 만드는 문제가 있음"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be8d0a3f72b29ba8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 구글은 짧은 문장. 요약문을 생성하는 모델을 딥 러닝을 통해 end-to-end로 설계하도록 했어요. 구글이 메일서비스에 적용한 자동 회신(Smart Reply) 기능을 만든 것과 비슷한 딥러닝 기법이기도 한 인코더와 디코더의 구조로 구성된 이 딥 러닝 아키텍처의 이름은 무엇일까요?\n",
    "\n",
    "구글이 메일서비스에 적용한 자동 회신(Smart Reply) 기능과 유사한 딥러닝 기법으로 구성된 딥 러닝 아키텍처의 이름은 \"Sequence-to-Sequence (Seq2Seq) 모델\"입니다. Seq2Seq 모델은 인코더와 디코더라는 두 개의 주요 구성 요소로 이루어져 있습니다.\n",
    "\n",
    "인코더는 입력 시퀀스(예: 원본 문장)를 고정된 크기의 잠재 벡터(latent vector)로 인코딩하는 역할을 합니다. 이 잠재 벡터는 입력 시퀀스의 의미와 정보를 담고 있습니다.\n",
    "\n",
    "디코더는 인코더에서 얻은 잠재 벡터를 기반으로 출력 시퀀스(예: 요약문)를 생성하는 역할을 합니다. 디코더는 시작 토큰을 입력으로 받아서 한 번에 하나의 토큰을 생성하며, 이전에 생성된 토큰들과 현재 상태를 사용하여 다음 토큰을 예측합니다. 이런 식으로 디코더가 한 단어(또는 문자) 씩 출력하여 최종적으로 요약문을 완성합니다.\n",
    "\n",
    "Seq2Seq 모델은 번역, 대화 생성, 요약 등 다양한 자연어 처리 작업에서 활용되며, 구글의 Smart Reply와 같이 짧은 문장에 대한 요약/응답 생성에도 사용됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d5c812bed00774"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-3. 인공 신경망으로 텍스트 요약 훈련시키기\n",
    "\n",
    "우리는 seq2seq 모델을 통해서 Abstractive summarization 방식의 텍스트 요약기를 만들어볼 거예요. seq2seq은 두 개의 RNN 아키텍처를 사용하여 입력 시퀀스로부터 출력 시퀀스를 생성해 내는 자연어 생성 모델입니다. 주로 뉴럴 기계번역에 사용되는 이 모델이 텍스트 요약에도 사용될 수 있을지 갸우뚱하실 수도 있겠지만, 원문을 요약문으로 번역한다고 생각한다면 전혀 무리가 없겠죠?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce61ac8c6477bd1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "seq2seq 개요\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-21-2.max-800x600.png)\n",
    "\n",
    "https://medium.com/dl-for-product-and-service/abstractive-text-summary-with-reinforcement-learning-ab2458ab29d5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9c6c1aedb9c12b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "원문을 첫 번째 RNN인 인코더로 입력하면, 인코더는 이를 하나의 고정된 벡터로 변환해요. 이 벡터를 문맥 정보를 가지고 있는 벡터라고 하여 컨텍스트 벡터(context vector)라고 합니다. 두 번째 RNN인 디코더는 이 컨텍스트 벡터를 전달받아 한 단어씩 생성해내서 요약 문장을 완성하는 거죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99b44bcc50c17d6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  LSTM과 컨텍스트 벡터\n",
    "\n",
    "우리는 seq2seq를 구현할 때, 인코더/디코더로 바닐라 RNN이 아니라 LSTM을 사용할 거예요.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/E-21-3.max-800x600.png)\n",
    "\n",
    "[RNN과 LSTM]\n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4a1d582f89e6133"
  },
  {
   "cell_type": "markdown",
   "source": [
    "LSTM이 바닐라 RNN과 다른 점은 다음 time step의 셀에 hidden state뿐만 아니라, cell state도 함께 전달한다는 점이에요. 다시 말해, 인코더가 디코더에 전달하는 컨텍스트 벡터 또한 hidden state h와 cell state c 두 개의 값 모두 존재해야 한다는 뜻이죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "110db78f1cae2649"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 시작 토큰과 종료 토큰\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-4.png)\n",
    "\n",
    "[시작 토큰 SOS와 종료 토큰 EOS는 각각 start of a sequence와 end of a sequence를 나타낸다]\n",
    "https://arxiv.org/pdf/1812.02303.pdf\n",
    "\n",
    "seq2seq 구조에서 디코더는 시작 토큰 SOS가 입력되면, 각 시점마다 단어를 생성하고 이 과정을 종료 토큰 EOS를 예측하는 순간까지 멈추지 않아요. 다시 말해 훈련 데이터의 예측 대상 시퀀스의 앞, 뒤에는 시작 토큰과 종료 토큰을 넣어주는 전처리를 통해 어디서 멈춰야 하는지 알려줄 필요가 있겠죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9057e8d089c80209"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 어텐션 메커니즘을 통한 새로운 컨텍스트 벡터 사용하기\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-5.png)\n",
    "\n",
    "[기존의 컨텍스트 벡터보다 인코더의 정보를 적극적으로 활용하여 성능을 끌어올리는 어텐션 메커니즘]\n",
    "https://arxiv.org/pdf/1812.02303.pdf\n",
    "\n",
    "우리는 기존에 배운 seq2seq를 수정하고, 새로운 모듈을 붙여 모델의 성능을 높여볼 거예요. 기존의 seq2seq는 인코더의 마지막 time step의 hidden state를 컨텍스트 벡터로 사용했어요. 하지만 RNN 계열의 인공 신경망(바닐라 RNN, LSTM, GRU)의 한계로 인해 이 컨텍스트 정보에는 이미 입력 시퀀스의 많은 정보가 손실이 된 상태가 됩니다.\n",
    "\n",
    "어텐션 메커니즘(Attention Mechanism) 은 이와 달리, 인코더의 모든 step의 hidden state의 정보가 컨텍스트 벡터에 전부 반영되도록 하는 것입니다. 하지만 인코더의 모든 hidden state가 동일한 비중으로 반영되는 것이 아니라, 디코더의 현재 time step의 예측에 인코더의 각 step이 얼마나 영향을 미치는지에 따른 가중합으로 계산되는 방식입니다.\n",
    "\n",
    "위 그림의 예로 들자면, seq2seq 모델이라면 디코더로 전달되는 인코더의 컨텍스트 벡터는 인코더의 마지막 스텝의 hidden state인 $h_5$ 가 되겠지만, 어텐션 메커니즘이 적용된 seq2seq인 Attentional seq2seq이라면 인코더의 컨텍스트 벡터는 예를 들어 $0.2h_1 + 0.3h_2 + 0.1h_3 + 0.15h_4 + 0.25h_5$ 가 될 수도 있는 것입니다.\n",
    "\n",
    "여기서 주의해야 할 것은, 컨텍스트 벡터를 구성하기 위한 인코더 hidden state의 가중치 값은 디코더의 현재 스텝이 어디냐에 따라 계속 달라진다는 점입니다. 즉, 디코더의 현재 문장 생성 부위가 주어부인지 술어부인지 목적어인지 등에 따라 인코더가 입력 데이터를 해석한 컨텍스트 벡터가 다른 값이 된다는 것입니다. 이와 달리, 기본적인 seq2seq 모델에서 컨텍스트 벡터는 디코더의 현재 스텝 위치에 무관하게 한번 계산되면 고정값을 가집니다.\n",
    "\n",
    "이렇게 디코더의 현재 스텝에 따라 동적으로 달라지는 인코더의 컨텍스트 벡터를 사용해서 현재의 예측에 활용하면, 디코더가 좀 더 정확한 예측을 할 수 있게 돼요. 이러한 Attention 기법은 seq2seq을 비롯하여 향후 다양한 딥러닝 분야를 획기적으로 발전시킨 핵심 개념이 됩니다. 특히 자연어처리 분야에서는 두말할 것도 없겠죠? 아직은 Attention 개념이 명확하게 와닿지 않을지라도, 앞으로도 수차례에 걸쳐 이 개념에 대해 더욱 깊이 있게 다루게 될 것입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14a5382d0ecb442"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. SOS 토큰과 EOS 토큰을 사용하는 이유가 무엇인가요?\n",
    "\n",
    "SOS 토큰은 디코더에 입력되는 첫 번째 토큰으로 사용되며, 디코더가 문장 생성을 시작하도록 합니다. EOS 토큰은 디코더가 문장 생성을 끝내야 할 때 사용되며, 디코더가 문장 생성을 멈추게 합니다. 즉, SOS 토큰과 EOS 토큰은 seq2seq 모델이 문장 생성을 시작하고 끝내는 시점을 알려주는 역할을 하기 위함 입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "938d518e5c6d2478"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Attention 모델과 seq2seq 모델의 차이점이 무엇인가요?\n",
    "\n",
    "Attention 모델에서는 모든 스텝의 hidden state의 정보가 컨텍스트 벡터에 반영됩니다. 그리고 디코더가 출력을 생성할 때, 컨텍스트 벡터에 반영된 각각의 hidden state에 대한 가중치 값은 디코더의 현재 스텝이 어딘지에 따라 다르게 반영됩니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65329f3d21ca99aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "지금까지의 내용을 정리해볼게요.\n",
    "\n",
    "seq2seq를 사용합니다.\n",
    "RNN 계열 중 LSTM을 사용하므로 hidden state뿐만 아니라 cell state도 사용해야 합니다.\n",
    "디코더의 예측 시퀀스에는 시작 토큰 SOS와 예측 토큰 EOS를 시퀀스의 앞, 뒤로 붙입니다.\n",
    "seq2seq를 구동시키면 디코더는 시작 토큰을 입력받아 예측을 시작합니다.\n",
    "seq2seq 기본 모델과 달리, 어텐션 메커니즘을 이용해 인코더의 hidden state의 중요도를 취합한 컨텍스트 벡터를 디코더 스텝별로 계산합니다.\n",
    "계산된 컨텍스트 벡터를 이용해서 디코더는 다음 등장할 단어를 예측합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa9a75b09c268de7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-4. 데이터 준비하기\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "feb5c46d8f28fd6e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$ mkdir -p ~/aiffel/news_summarization/data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa0e74c09bd9e89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "오늘 우리가 텍스트 요약 모델 학습에 사용할 데이터셋은 Kaggle에서 제공된 아마존 리뷰 데이터셋입니다.\n",
    "\n",
    "https://d3s0tskafalll9.cloudfront.net/media/documents/Reviews.csv.zip"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T05:49:34.328111Z",
     "start_time": "2023-09-13T05:49:34.095328Z"
    }
   },
   "id": "a316e0b3f398affc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "$ ln -s ~/data/*.csv ~/aiffel/news_summarization/data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b22300c492e27563"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이번 실습에서는 NLTK의 불용어(stopwords)를 사용할 거에요. NTLK와 NLTK 데이터셋이 설치되어 있지 않은 환경이라면 우선 NLTK를 설치하고 NTLK의 데이터셋을 다운로드해 주세요.\n",
    "\n",
    "NLTK는 Natural Language Toolkit의 축약어로 영어 기호, 통계, 자연어 처리를 위한 라이브러리에요. 이 NLTK에는 I, my, me, over, 조사, 접미사와 같이 문장에는 자주 등장하지만, 의미를 분석하고 요약하는 데는 거의 의미가 없는 100여개의 불용어가 미리 정리되어 있어요. 이를 이용해 다운로드한 리뷰 파일에서 불용어를 제거하는 작업을 진행할 예정이에요.\n",
    "\n",
    "NLTK 패키지에서 불용어 사전을 다운로드하고, 데이터 전처리를 위한 나머지 패키지도 함께 불러와 볼까요."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-13T05:49:34.144608Z"
    }
   },
   "id": "ff65bea870492d83"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\r\n",
      "/home/ralphpark/.bashrc: line 1: syntax error near unexpected token `('\r\n",
      "/home/ralphpark/.bashrc: line 1: `i# ~/.bashrc: executed by bash(1) for non-login shells.'\r\n",
      "Defaulting to user installation because normal site-packages is not writeable\r\n",
      "Requirement already satisfied: nltk in /home/ralphpark/.local/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /home/ralphpark/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ralphpark/.local/lib/python3.10/site-packages (from nltk) (2023.8.8)\r\n",
      "Requirement already satisfied: tqdm in /home/ralphpark/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\r\n",
      "Requirement already satisfied: joblib in /home/ralphpark/.local/lib/python3.10/site-packages (from nltk) (1.3.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:32:13.880883Z",
     "start_time": "2023-09-13T16:32:13.398967Z"
    }
   },
   "id": "78ffb607d409da10"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ralphpark/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('=3')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:38:43.782152Z",
     "start_time": "2023-09-13T16:38:43.721873Z"
    }
   },
   "id": "729c233293c367f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "링크에서 다운로드 받은 데이터(Reviews.csv)는 총 568,454개의 샘플을 갖고 있어요. 시간상 여기서는 모든 샘플을 사용하지는 않고, 간단히 10만 개의 샘플만 사용해볼게요."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T05:02:54.116275Z",
     "start_time": "2023-09-13T05:02:39.098583Z"
    }
   },
   "id": "1228d4d9d4f34702"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/ralphpark/aiffel'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:38:49.131130Z",
     "start_time": "2023-09-13T16:38:49.064637Z"
    }
   },
   "id": "a6faa537a9259595"
  },
  {
   "cell_type": "markdown",
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6307394859ac9b39"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows=100000)\n",
    "print('전체 샘플수 :', (len(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:38:51.242322Z",
     "start_time": "2023-09-13T16:38:50.852235Z"
    }
   },
   "id": "1d76b61c618bb80a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "출력된 샘플 수를 보면 총 10만 개의 샘플이 잘 불러와진 것을 확인할 수 있습니다. 이 중에 5개만 출력해볼까요?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e756d9b19aabf2b5"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:38:52.603405Z",
     "start_time": "2023-09-13T16:38:52.527993Z"
    }
   },
   "id": "e5fa0829103ed24a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "열이 너무 많아서 보기에 조금 까다롭죠. 사실 전체 데이터 중 Summary 열과 Text 열만 훈련에 사용할 거라, 이 두 개의 열만 별도로 저장하고, 다시 출력해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c771600a20200da0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 데이터프레임 data의 Text와 Summary 컬럼의 데이터만 남기는 코드를 작성하세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3582d1e8ef7966f5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    Text  \\\n44427  This is great to keep your puppy or older dog ...   \n98314  At 80 cents a piece these are a good deal. The...   \n52564  I don't know how I could say whether or not th...   \n85509  Absolutely horrible beef jerkey. It is really ...   \n25336  It was time to order cat food again and I thou...   \n57874  This 5 lb bag is the best deal for the Haribo ...   \n89148  I am very pleased with this product.  Deliciou...   \n53535  Actually love this product 2 packets a day and...   \n20484  Our cats usually get the \"green can\" Fancy Fea...   \n76689  I love this coffee.Ive tried them all and I ca...   \n64544  Obviously rice isn't a low-carb food per se, b...   \n83367  These K-Cups from San Francisco Bay Coffee hav...   \n23896  I accidentally bought these chips (thought I w...   \n1124   3 boxes, under $6 each for all cherry - great ...   \n1688   I'm trying to eat healthier and one of the thi...   \n\n                                                 Summary  \n44427                               My dog love this !!!  \n98314                                              tasty  \n52564                          My Kitty Seems To Love It  \n85509         Worst beef jerkey I've ever \"tried\" to eat  \n25336                 The Cats Gave This Two Thumbs Down  \n57874                       Best Deal for Haribo Gummies  \n89148                                         Good stuff  \n53535                                       Fluid Intake  \n20484  More watery than expected; cats are not digest...  \n76689                   It makes me want to fix stuff!!!  \n64544                          Great for carb management  \n83367                                     NOT A GOOD FIT  \n23896                 Makes you pucker, but tastes good.  \n1124          All cherry - I couldn't find it in stores.  \n1688         Popchips Satisfy my Salt and Crunch Craving  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>44427</th>\n      <td>This is great to keep your puppy or older dog ...</td>\n      <td>My dog love this !!!</td>\n    </tr>\n    <tr>\n      <th>98314</th>\n      <td>At 80 cents a piece these are a good deal. The...</td>\n      <td>tasty</td>\n    </tr>\n    <tr>\n      <th>52564</th>\n      <td>I don't know how I could say whether or not th...</td>\n      <td>My Kitty Seems To Love It</td>\n    </tr>\n    <tr>\n      <th>85509</th>\n      <td>Absolutely horrible beef jerkey. It is really ...</td>\n      <td>Worst beef jerkey I've ever \"tried\" to eat</td>\n    </tr>\n    <tr>\n      <th>25336</th>\n      <td>It was time to order cat food again and I thou...</td>\n      <td>The Cats Gave This Two Thumbs Down</td>\n    </tr>\n    <tr>\n      <th>57874</th>\n      <td>This 5 lb bag is the best deal for the Haribo ...</td>\n      <td>Best Deal for Haribo Gummies</td>\n    </tr>\n    <tr>\n      <th>89148</th>\n      <td>I am very pleased with this product.  Deliciou...</td>\n      <td>Good stuff</td>\n    </tr>\n    <tr>\n      <th>53535</th>\n      <td>Actually love this product 2 packets a day and...</td>\n      <td>Fluid Intake</td>\n    </tr>\n    <tr>\n      <th>20484</th>\n      <td>Our cats usually get the \"green can\" Fancy Fea...</td>\n      <td>More watery than expected; cats are not digest...</td>\n    </tr>\n    <tr>\n      <th>76689</th>\n      <td>I love this coffee.Ive tried them all and I ca...</td>\n      <td>It makes me want to fix stuff!!!</td>\n    </tr>\n    <tr>\n      <th>64544</th>\n      <td>Obviously rice isn't a low-carb food per se, b...</td>\n      <td>Great for carb management</td>\n    </tr>\n    <tr>\n      <th>83367</th>\n      <td>These K-Cups from San Francisco Bay Coffee hav...</td>\n      <td>NOT A GOOD FIT</td>\n    </tr>\n    <tr>\n      <th>23896</th>\n      <td>I accidentally bought these chips (thought I w...</td>\n      <td>Makes you pucker, but tastes good.</td>\n    </tr>\n    <tr>\n      <th>1124</th>\n      <td>3 boxes, under $6 each for all cherry - great ...</td>\n      <td>All cherry - I couldn't find it in stores.</td>\n    </tr>\n    <tr>\n      <th>1688</th>\n      <td>I'm trying to eat healthier and one of the thi...</td>\n      <td>Popchips Satisfy my Salt and Crunch Craving</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임 data의 Text와 Summary 컬럼의 데이터만 남기는 코드\n",
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:38:55.043990Z",
     "start_time": "2023-09-13T16:38:54.975931Z"
    }
   },
   "id": "982e69ebe32dec84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-5. 데이터 전처리하기 (1) 데이터 정리하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca48cf279223b18d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 데이터를 불러왔으니 전처리를 진행해 볼게요. 빈칸으로 존재하는 null 데이터, 의미는 같지만 다른 식으로 작성된 글 같은 중복 항목과 같은 학습할 때 방해가 되는 데이터를 먼저 솎아낼 거예요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c44b8cbbd300c6e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 중복 샘플과 NULL 값이 존재하는 샘플 제거\n",
    "\n",
    "우선 데이터의 중복 샘플 유무를 확인해 볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61a82160e128cf0f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:38:57.852275Z",
     "start_time": "2023-09-13T16:38:57.720158Z"
    }
   },
   "id": "144a4d9857c73a98"
  },
  {
   "cell_type": "markdown",
   "source": [
    "중복을 제외한다면 Text에는 88,426개, Summary에는 72,348개의 유니크한 데이터가 존재해요. 사실 이 데이터의 Summary는 'Smelly'나 'Good Product'와 같이 아주 간단한 요약들도 많아서 Text가 달라도 Summary는 동일할 수 있어요. 하지만 Text 자체가 중복이 된 경우는 중복 샘플이므로 제거해야겠죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bbed9136a6f2adc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "데이터프레임의 drop_duplicates()를 사용하면, 손쉽게 중복 샘플을 제거할 수 있어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8056753e470c7c61"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['Text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:00.137997Z",
     "start_time": "2023-09-13T16:39:00.077432Z"
    }
   },
   "id": "4136fed6adc7ac05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "중복이 제거되면서 샘플 수가 88,426개로 줄어들었어요. 그런데 만약 데이터 Null 값을 가지는 샘플이 있었다면, drop_duplicates()가 중복된 Null들을 지워주기는 하겠지만, 여전히 Null 값 한 개가 어딘가 남아있을 수 있어요. 데이터에 Null 값이 남아있는지 볼게요.\n",
    "\n",
    "데이터프레임에 Null 값이 있는지 확인하는 방법은 .isnull().sum()을 사용하면 알아볼 수 있어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb941b87d4339982"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:01.630200Z",
     "start_time": "2023-09-13T16:39:01.558107Z"
    }
   },
   "id": "c385953e8f8fd70b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summary에 1개의 Null 값이 있네요. 데이터프레임에서 Null을 제거할 때는 dropna() 함수를 사용하면 돼요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2a8ba6b3c94b3bb"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:03.783908Z",
     "start_time": "2023-09-13T16:39:03.721432Z"
    }
   },
   "id": "3811ea799aa1d066"
  },
  {
   "cell_type": "markdown",
   "source": [
    "전체 샘플 수가 1개 줄어들어 88,425개의 샘플이 남았네요. 지금까지 중복 샘플과 Null 값이 있는 샘플들을 제거해보았는데 10만 개의 샘플 중 1만 개 이상의 샘플이 제거되었어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11e027446f16251c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 텍스트 정규화와 불용어 제거\n",
    "\n",
    "살아남은 88,425개의 샘플에는 수많은 단어들이 있어요. 그런데 사실 그 단어들 중에서는 같은 의미인데도 다른 표현으로 쓰여 마치 다른 단어들처럼 간주되는 경우가 있어요.\n",
    "\n",
    "예를 들어서 it'll은 it will과 같고, mustn't과 must not은 사실 같은 표현이죠. 이런 경우 기계가 굳이 이들을 마치 다른 단어로 간주하게 해서 연산량을 늘리는 것보다는 기계 학습 전에 미리 같은 표현으로 통일시켜주는 것이 기계의 연산량을 줄일 수 있는 방법이에요.\n",
    "\n",
    "이러한 방법론을 텍스트 처리에서는 텍스트 정규화(text normalization) 라고 해요.\n",
    "\n",
    "여기서는 텍스트 정규화를 위한 사전(dictionary)을 아래와 같이 구성할 거예요. 이 사전은 아래의 링크에서 참고하여 만들었어요.\n",
    "\n",
    "정규화 사전 출처\n",
    "https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9ca33932e973c38"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:05.774229Z",
     "start_time": "2023-09-13T16:39:05.692512Z"
    }
   },
   "id": "d2c010cadd818ec2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 정규화 준비까지 마쳤어요.\n",
    "\n",
    "하지만 아직 끝난 게 아니에요. 일반적으로 텍스트에는 자주 등장하지만 자연어 처리를 할 때 실질적으로 별 도움이 되지 않는 단어들이 존재해요. 이를 불용어(stopwords)라고 불러요. 때로는 불용어를 제거하는 것이 자연어 처리의 성능을 높이는 방법일 수 있어요. 여기서는 NLTK에서 제공하는 불용어 리스트를 참조해, 샘플에서 불용어를 제거할 거예요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b7acecaf11d562f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:07.359359Z",
     "start_time": "2023-09-13T16:39:07.279142Z"
    }
   },
   "id": "f1883262fc935566"
  },
  {
   "cell_type": "markdown",
   "source": [
    "NLTK에서 미리 정의하여 제공하고 있는 불용어는 총 179개라는 것을 볼 수 있죠. 이를 사용하여 불용어를 제거할 거예요. 이 작업 외에도 모든 영어 문자는 소문자로 만들고, 섞여있는 html 태그를 제거하고, 정규 표현식을 통해 각종 특수문자를 제거해서 정말 필요한 내용만 잘 학습할 수 있도록 처리할 거예요.\n",
    "\n",
    "함수의 하단을 보면, NLTK를 이용해 불용어를 제거하는 파트가 있는데, 이는 Text 전처리 시에서만 호출하고 이미 상대적으로 문장 길이가 짧은 Summary 전처리할 때는 호출하지 않을 예정이에요. Abstractive한 문장 요약 결과문이 자연스러운 문장이 되려면 이 불용어들이 Summary에는 남아 있는 게 더 좋을 것 같습니다. 이 처리를 위해서 함수의 인자로 remove_stopwords를 추가하고, if문을 추가했어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a416d3e53e1b125d"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:08.513804Z",
     "start_time": "2023-09-13T16:39:08.459640Z"
    }
   },
   "id": "38e29397fcb1c490"
  },
  {
   "cell_type": "markdown",
   "source": [
    "전처리 전, 후의 결과를 확인하기 위해서 임의의 text와 summary를 만들어 함수를 호출해 볼까요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3683ee6fea8b2b21"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  everything bought great infact ordered twice third ordered wasfor mother father\n",
      "summary: great way to start the day\n"
     ]
    }
   ],
   "source": [
    "\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(\"text: \", preprocess_sentence(temp_text))\n",
    "print(\"summary:\", preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:39:10.398911Z",
     "start_time": "2023-09-13T16:39:10.330687Z"
    }
   },
   "id": "3d449b2fead7b3e9"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "24c040fbbd51bf01"
  },
  {
   "cell_type": "markdown",
   "source": [
    "결과를 보면 기본적으로 모든 알파벳이 소문자로 변환되고, <br />과 같은 html 태그가 제거되었죠. (or finish)와 같은 괄호로 묶였던 단어 시퀀스가 제거된 것도 확인할 수 있어요. 또한 특수문자가 제거되면서 영어만 남았어요.\n",
    "\n",
    "이제 함수가 잘 작동하는 것을 확인했으니, 훈련 데이터 전체에 대해서 전처리를 수행해볼게요. 이때, Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않을 것이므로 따로 호출해서 진행해야 해요. 먼저 Text를 전처리하고, 결과를 확인하기 위해서 상위 5개의 줄을 출력해볼게요.\n",
    "\n",
    "Q. 위의 내용을 참고해서 훈련 데이터 전체의 Text 컬럼의 데이터를 전처리하는 코드를 작성하세요.(반복문 사용)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa3a3863c668b3bd"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50325/998782171.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 전처리 후 결과:  ['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n"
     ]
    }
   ],
   "source": [
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "# 훈련 데이터 전체의 Text 컬럼의 데이터를 전처리하는 코드를 작성\n",
    "clean_text = []\n",
    "\n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "\n",
    "# 전처리 후 출력\n",
    "print(\"Text 전처리 후 결과: \", clean_text[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:45:19.904120Z",
     "start_time": "2023-09-13T16:39:12.538245Z"
    }
   },
   "id": "d44f4ff90feb14bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 Summary에 대해서 전처리 함수를 호출해 줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False를 넣어줄게요.\n",
    "\n",
    "Q. 위의 내용을 참고해서 훈련 데이터 전체의 Summary 컬럼의 데이터를 전처리하는 코드를 작성하세요.(반복문 사용)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5913adaf9a73ab1d"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_50325/998782171.py:4: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
      "/tmp/ipykernel_50325/998782171.py:4: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary 전처리 후 결과:  ['good quality dog food', 'not as advertised', 'delight says it all', 'cough medicine', 'great taffy']\n"
     ]
    }
   ],
   "source": [
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "clean_summary = []\n",
    "\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "print(\"Summary 전처리 후 결과: \", clean_summary[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:45:43.547897Z",
     "start_time": "2023-09-13T16:45:33.075057Z"
    }
   },
   "id": "87ebd179b4416ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이렇게 텍스트 정제의 과정을 거친 후에는 다시 한번 빈(empty) 샘플이 생겼는지 확인해보는 것이 좋아요. 정제 전에는 데이터가 존재했지만, 정제 과정에서 문장의 모든 단어가 사라지는 경우가 있을 수 있어요. 이렇게 되면 샘플 자체가 빈 값을 가지게 되겠죠.\n",
    "\n",
    "보다 쉽게 확인하기 위해 데이터들을 데이터프레임에 재저장할게요. 빈(empty) 값을 가진 샘플들이 있다면, 모두 Null 값을 가진 샘플로 대체해요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac3eb235cb9e194d"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:45:50.126240Z",
     "start_time": "2023-09-13T16:45:50.050878Z"
    }
   },
   "id": "350075be66faf23e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이전과 같이 .isnull().sum()을 사용해서 Null 값이 생겼는지 해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e69b8540280e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "Text        0\nSummary    70\ndtype: int64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:45:52.388463Z",
     "start_time": "2023-09-13T16:45:52.311511Z"
    }
   },
   "id": "3d8fc732396c6e59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summary 열에서 70개의 Null 값이 생겼네요. 원래는 단어가 있었는데, 정제 과정에서 모든 단어가 제거되어 빈 샘플이 70개나 생겼다는 의미예요. 이 샘플들은 모두 제거해줄게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1233ef8a07defc8c"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:45:54.958180Z",
     "start_time": "2023-09-13T16:45:54.893526Z"
    }
   },
   "id": "2040549dafc6182b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-6. 데이터 전처리하기 (2) 훈련데이터와 테스트데이터 나누기\n",
    "\n",
    "학습을 진행하기 위해서는 학습에 사용할 데이터의 크기를 결정하고, 문장의 시작과 끝을 표시해 줘야 해요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27c27ac3ed8c168f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 샘플의 최대 길이 정하기\n",
    "\n",
    "필요 없는 단어를 모두 솎아낸 데이터를 가지게 되었으니, 이제 훈련에 사용할 샘플의 최대 길이를 정해줄 차례에요.\n",
    "\n",
    "Text와 Summary의 최소, 최대, 평균 길이를 구하고 또한 길이 분포를 시각화해서 볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3dee094a9d09a75"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk0AAAHHCAYAAACiOWx7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABBe0lEQVR4nO3dfVhUdf7/8deAcqcO5A2gCWplKXmXoIh2s5skGdWauqXrKpndaGgqZeimlrWJW1upabrmJu2uprmb7q4kZnj3K8kbFBNTMsNwVwFNYdQUFM7vj76cdYLyjIEz4vNxXXNdzfm85zPv89nFeV3nnDljMwzDEAAAAH6Sl7sbAAAAuBIQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBqPNsNpulx4YNG2rk/Q4fPqwXXnhB2dnZNTIfAM9Qz90NAEBt++tf/+r0/C9/+YvWrl1bZXv79u1r5P0OHz6sadOmqXXr1urSpUuNzAnA/QhNAOq83/72t07PP/vsM61du7bKdgD4KZyeAwBJFRUVmjlzpm6++Wb5+fkpJCRETzzxhE6cOGHWPP/88/Ly8lJGRobTax9//HH5+Pho165d2rBhg7p16yZJGj58uHnqLzU19XLuDoBaQGgCAElPPPGEJkyYoF69emnWrFkaPny4Fi9erLi4OJ07d06SNHnyZHXp0kUjRozQyZMnJUlr1qzR22+/ralTp6pz585q3769XnzxRUnfh6m//vWv+utf/6rbb7/dbfsGoGbYDMMw3N0EAFxOo0eP1ty5c1X5z98nn3yi2267TYsXL9ZvfvMbs27NmjW6++67nbbn5OQoMjJSw4YN06uvvqoOHTqoefPmyszMVL1631/xsH37dnXr1k2LFi3Sww8/fNn3D0Dt4EgTgKve8uXLFRgYqLvuukvHjh0zH5GRkWrYsKHWr19v1nbo0EHTpk3TwoULFRcXp2PHjundd981AxOAuou/cgBXvf3796ukpETBwcHVjhcVFTk9nzBhgpYuXaqtW7dq+vTpioiIuBxtAnAzQhOAq15FRYWCg4O1ePHiasebNWvm9Pzrr7/W/v37JUm7d++u9f4AeAZCE4Cr3vXXX6+PP/5YvXr1kr+//0/WVlRU6OGHH5bdbte4ceM0ffp0DRw4UP379zdrbDZbbbcMwA24pgnAVe/BBx9UeXm5XnrppSpj58+fV3Fxsfn89ddf1+bNm7VgwQK99NJL6tmzp0aNGqVjx46ZNQ0aNJAkp9cBuPJxpAnAVe+OO+7QE088oZSUFGVnZ6tPnz6qX7++9u/fr+XLl2vWrFkaOHCg9u7dqylTpujhhx/WfffdJ0lKTU1Vly5d9OSTT+r999+X9P2Rq6CgIM2fP1+NGjVSgwYNFB0drTZt2rhzNwH8TBxpAgBJ8+fP14IFC1RUVKTf/e53mjRpktatW6ff/va36tWrl8rLy5WQkKCmTZtq5syZ5uvatm2rlJQULV++3AxN9evX17vvvitvb2+NHDlSgwcP1saNG920ZwBqCvdpAgAAsIAjTQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACbm5ZQyoqKnT48GE1atSIn1AAAOAKYRiGTp48qRYtWsjL66ePJRGaasjhw4cVFhbm7jYAAMAlOHTokFq2bPmTNYSmGtKoUSNJ3y+63W53czcAAMAKh8OhsLAw83P8pxCaakjlKTm73U5oAgDgCmPl0houBAcAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALKjn7gZgTeuJaZZrD86Ir8VOAAC4OnGkCQAAwAJCEwAAgAWEJgAAAAsITQAAABa4NTS98MILstlsTo927dqZ42fPnlViYqKaNGmihg0basCAASosLHSaIz8/X/Hx8QoICFBwcLAmTJig8+fPO9Vs2LBBXbt2la+vr2644QalpqZW6WXu3Llq3bq1/Pz8FB0dra1bt9bKPgMAgCuT24803XzzzTpy5Ij5+OSTT8yx8ePH69///reWL1+ujRs36vDhw+rfv785Xl5ervj4eJWVlWnz5s169913lZqaqqlTp5o1eXl5io+P1y9/+UtlZ2dr3LhxevTRR7VmzRqzZtmyZUpKStLzzz+vHTt2qHPnzoqLi1NRUdHlWQQAAODxbIZhGO568xdeeEErV65UdnZ2lbGSkhI1a9ZMS5Ys0cCBAyVJ+/btU/v27ZWZmakePXpo9erVuvfee3X48GGFhIRIkubPn6/k5GQdPXpUPj4+Sk5OVlpamnJycsy5Bw0apOLiYqWnp0uSoqOj1a1bN82ZM0eSVFFRobCwMI0ZM0YTJ060tC8Oh0OBgYEqKSmR3W7/OctSLW45AABAzXPl89vtR5r279+vFi1a6LrrrtOQIUOUn58vScrKytK5c+cUGxtr1rZr107h4eHKzMyUJGVmZqpjx45mYJKkuLg4ORwO7dmzx6y5cI7Kmso5ysrKlJWV5VTj5eWl2NhYs6Y6paWlcjgcTg8AAFB3uTU0RUdHKzU1Venp6Zo3b57y8vJ022236eTJkyooKJCPj4+CgoKcXhMSEqKCggJJUkFBgVNgqhyvHPupGofDoTNnzujYsWMqLy+vtqZyjuqkpKQoMDDQfISFhV3SGgAAgCuDW+8I3rdvX/O/O3XqpOjoaLVq1Urvv/++/P393djZxU2aNElJSUnmc4fDQXACAKAOc/vpuQsFBQXpxhtv1FdffaXQ0FCVlZWpuLjYqaawsFChoaGSpNDQ0Crfpqt8frEau90uf39/NW3aVN7e3tXWVM5RHV9fX9ntdqcHAACouzwqNJ06dUoHDhxQ8+bNFRkZqfr16ysjI8Mcz83NVX5+vmJiYiRJMTEx2r17t9O33NauXSu73a6IiAiz5sI5Kmsq5/Dx8VFkZKRTTUVFhTIyMswaAAAAt4amZ555Rhs3btTBgwe1efNmPfDAA/L29tbgwYMVGBioESNGKCkpSevXr1dWVpaGDx+umJgY9ejRQ5LUp08fRUREaOjQodq1a5fWrFmjyZMnKzExUb6+vpKkkSNH6uuvv9azzz6rffv26a233tL777+v8ePHm30kJSXp7bff1rvvvqu9e/dq1KhROn36tIYPH+6WdQEAAJ7Hrdc0/ec//9HgwYP17bffqlmzZrr11lv12WefqVmzZpKkN954Q15eXhowYIBKS0sVFxent956y3y9t7e3Vq1apVGjRikmJkYNGjRQQkKCXnzxRbOmTZs2SktL0/jx4zVr1iy1bNlSCxcuVFxcnFnz0EMP6ejRo5o6daoKCgrUpUsXpaenV7k4HAAAXL3cep+muoT7NAEAcOW5ou7TBAAAcCUgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAs8JjQNGPGDNlsNo0bN87cdvbsWSUmJqpJkyZq2LChBgwYoMLCQqfX5efnKz4+XgEBAQoODtaECRN0/vx5p5oNGzaoa9eu8vX11Q033KDU1NQq7z937ly1bt1afn5+io6O1tatW2tjNwEAwBXKI0LTtm3b9Kc//UmdOnVy2j5+/Hj9+9//1vLly7Vx40YdPnxY/fv3N8fLy8sVHx+vsrIybd68We+++65SU1M1depUsyYvL0/x8fH65S9/qezsbI0bN06PPvqo1qxZY9YsW7ZMSUlJev7557Vjxw517txZcXFxKioqqv2dBwAAVwSbYRiGOxs4deqUunbtqrfeeku///3v1aVLF82cOVMlJSVq1qyZlixZooEDB0qS9u3bp/bt2yszM1M9evTQ6tWrde+99+rw4cMKCQmRJM2fP1/Jyck6evSofHx8lJycrLS0NOXk5JjvOWjQIBUXFys9PV2SFB0drW7dumnOnDmSpIqKCoWFhWnMmDGaOHGipf1wOBwKDAxUSUmJ7HZ7TS6RJKn1xDTLtQdnxNf4+wMAUBe58vnt9iNNiYmJio+PV2xsrNP2rKwsnTt3zml7u3btFB4erszMTElSZmamOnbsaAYmSYqLi5PD4dCePXvMmh/OHRcXZ85RVlamrKwspxovLy/FxsaaNdUpLS2Vw+FwegAAgLqrnjvffOnSpdqxY4e2bdtWZaygoEA+Pj4KCgpy2h4SEqKCggKz5sLAVDleOfZTNQ6HQ2fOnNGJEydUXl5ebc2+fft+tPeUlBRNmzbN2o4CAIArntuONB06dEhjx47V4sWL5efn5642LtmkSZNUUlJiPg4dOuTulgAAQC1yW2jKyspSUVGRunbtqnr16qlevXrauHGjZs+erXr16ikkJERlZWUqLi52el1hYaFCQ0MlSaGhoVW+TVf5/GI1drtd/v7+atq0qby9vautqZyjOr6+vrLb7U4PAABQd7ktNPXu3Vu7d+9Wdna2+YiKitKQIUPM/65fv74yMjLM1+Tm5io/P18xMTGSpJiYGO3evdvpW25r166V3W5XRESEWXPhHJU1lXP4+PgoMjLSqaaiokIZGRlmDQAAgNuuaWrUqJE6dOjgtK1BgwZq0qSJuX3EiBFKSkpS48aNZbfbNWbMGMXExKhHjx6SpD59+igiIkJDhw7VK6+8ooKCAk2ePFmJiYny9fWVJI0cOVJz5szRs88+q0ceeUTr1q3T+++/r7S0/30bLSkpSQkJCYqKilL37t01c+ZMnT59WsOHD79MqwEAADydWy8Ev5g33nhDXl5eGjBggEpLSxUXF6e33nrLHPf29taqVas0atQoxcTEqEGDBkpISNCLL75o1rRp00ZpaWkaP368Zs2apZYtW2rhwoWKi4szax566CEdPXpUU6dOVUFBgbp06aL09PQqF4cDAICrl9vv01RXcJ8mAACuPFfUfZoAAACuBIQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFPzs0ORwOrVy5Unv37q2JfgAAADySy6HpwQcf1Jw5cyRJZ86cUVRUlB588EF16tRJ//jHP2q8QQAAAE/gcmjatGmTbrvtNknSihUrZBiGiouLNXv2bP3+97+v8QYBAAA8gcuhqaSkRI0bN5Ykpaena8CAAQoICFB8fLz2799f4w0CAAB4ApdDU1hYmDIzM3X69Gmlp6erT58+kqQTJ07Iz8+vxhsEAADwBPVcfcG4ceM0ZMgQNWzYUOHh4frFL34h6fvTdh07dqzp/gAAADyCy6HpySefVPfu3XXo0CHddddd8vL6/mDVddddxzVNAACgznI5NElSVFSUOnXqpLy8PF1//fWqV6+e4uPja7o3AAAAj+HyNU3fffedRowYoYCAAN18883Kz8+XJI0ZM0YzZsyo8QYBAAA8gcuhadKkSdq1a5c2bNjgdOF3bGysli1bVqPNAQAAeAqXT8+tXLlSy5YtU48ePWSz2cztN998sw4cOFCjzQEAAHgKl480HT16VMHBwVW2nz592ilEAQAA1CUuh6aoqCilpaWZzyuD0sKFCxUTE1NznQEAAHgQl0/PTZ8+XX379tUXX3yh8+fPa9asWfriiy+0efNmbdy4sTZ6BAAAcDuXjzTdeuutys7O1vnz59WxY0d99NFHCg4OVmZmpiIjI2ujRwAAALe7pPs0XX/99Xr77bdruhcAAACPZSk0ORwOyxPa7fZLbgYAAMBTWQpNQUFBF/1mnGEYstlsKi8vr5HGAAAAPIml0LR+/fra7gMAAMCjWQpNd9xxR233AQAA4NEu6ULwEydO6M9//rP27t0rSYqIiNDw4cPVuHHjGm0OAADAU7h8y4FNmzapdevWmj17tk6cOKETJ05o9uzZatOmjTZt2lQbPQIAALidy0eaEhMT9dBDD2nevHny9vaWJJWXl+vJJ59UYmKidu/eXeNNAgAAuJvLR5q++uorPf3002ZgkiRvb28lJSXpq6++qtHmAAAAPIXLoalr167mtUwX2rt3rzp37lwjTQEAAHgal0/PPfXUUxo7dqy++uor9ejRQ5L02Wefae7cuZoxY4Y+//xzs7ZTp0411ykAAIAb2QzDMFx5gZfXTx+cstlsV+WNLh0OhwIDA1VSUlIrd0VvPTHNcu3BGfE1/v4AANRFrnx+u3ykKS8v75IbAwAAuFK5HJpatWpVG30AAAB4tEu6ueXhw4f1ySefqKioSBUVFU5jTz31VI00BgAA4ElcDk2pqal64okn5OPjoyZNmjj9kK/NZiM0AQCAOsnl0DRlyhRNnTpVkyZNuuhF4QAAAHWFy6nnu+++06BBgwhMAADgquJy8hkxYoSWL19eG70AAAB4LJdPz6WkpOjee+9Venq6OnbsqPr16zuNv/766zXWHAAAgKe4pNC0Zs0a3XTTTZJU5UJwAACAusjl0PTaa6/pnXfe0cMPP1wL7QAAAHgml69p8vX1Va9evWqjFwAAAI/lcmgaO3as3nzzzdroBQAAwGO5fHpu69atWrdunVatWqWbb765yoXgH3zwQY01BwAA4ClcDk1BQUHq379/bfQCAADgsVw+Pbdo0aKffLhi3rx56tSpk+x2u+x2u2JiYrR69Wpz/OzZs0pMTFSTJk3UsGFDDRgwQIWFhU5z5OfnKz4+XgEBAQoODtaECRN0/vx5p5oNGzaoa9eu8vX11Q033KDU1NQqvcydO1etW7eWn5+foqOjtXXrVpf2BQAA1G1uva13y5YtNWPGDGVlZWn79u2688479atf/Up79uyRJI0fP17//ve/tXz5cm3cuFGHDx92OspVXl6u+Ph4lZWVafPmzXr33XeVmpqqqVOnmjV5eXmKj4/XL3/5S2VnZ2vcuHF69NFHtWbNGrNm2bJlSkpK0vPPP68dO3aoc+fOiouLU1FR0eVbDAAA4NFshmEYrr7o73//u95//33l5+errKzMaWzHjh0/q6HGjRvr1Vdf1cCBA9WsWTMtWbJEAwcOlCTt27dP7du3V2Zmpnr06KHVq1fr3nvv1eHDhxUSEiJJmj9/vpKTk3X06FH5+PgoOTlZaWlpysnJMd9j0KBBKi4uVnp6uiQpOjpa3bp105w5cyRJFRUVCgsL05gxYzRx4kRLfTscDgUGBqqkpER2u/1nrUF1Wk9Ms1x7cEZ8jb8/AAB1kSuf3y4faZo9e7aGDx+ukJAQ7dy5U927d1eTJk309ddfq2/fvpfcdHl5uZYuXarTp08rJiZGWVlZOnfunGJjY82adu3aKTw8XJmZmZKkzMxMdezY0QxMkhQXFyeHw2EercrMzHSao7Kmco6ysjJlZWU51Xh5eSk2NtasqU5paakcDofTAwAA1F0uh6a33npLCxYs0JtvvikfHx89++yzWrt2rZ566imVlJS43MDu3bvVsGFD+fr6auTIkVqxYoUiIiJUUFAgHx8fBQUFOdWHhISooKBAklRQUOAUmCrHK8d+qsbhcOjMmTM6duyYysvLq62pnKM6KSkpCgwMNB9hYWEu7zsAALhyuBya8vPz1bNnT0mSv7+/Tp48KUkaOnSo3nvvPZcbuOmmm5Sdna0tW7Zo1KhRSkhI0BdffOHyPJfbpEmTVFJSYj4OHTrk7pYAAEAtcjk0hYaG6vjx45Kk8PBwffbZZ5K+v+D6Ei6Pko+Pj2644QZFRkYqJSVFnTt31qxZsxQaGqqysjIVFxc71RcWFio0NNTs5Yffpqt8frEau90uf39/NW3aVN7e3tXWVM5RHV9fX/Nbf5UPAABQd7kcmu68807961//kiQNHz5c48eP11133aWHHnpIDzzwwM9uqKKiQqWlpYqMjFT9+vWVkZFhjuXm5io/P18xMTGSpJiYGO3evdvpW25r166V3W5XRESEWXPhHJU1lXP4+PgoMjLSqaaiokIZGRlmDQAAgMs3t1ywYIEqKiokybyH0ubNm3X//ffriSeecGmuSZMmqW/fvgoPD9fJkye1ZMkSbdiwQWvWrFFgYKBGjBihpKQkNW7cWHa7XWPGjFFMTIx69OghSerTp48iIiI0dOhQvfLKKyooKNDkyZOVmJgoX19fSdLIkSM1Z84cPfvss3rkkUe0bt06vf/++0pL+9+30ZKSkpSQkKCoqCh1795dM2fO1OnTpzV8+HBXlwcAANRRLocmLy8veXn97wDVoEGDNGjQoEt686KiIg0bNkxHjhxRYGCgOnXqpDVr1uiuu+6SJL3xxhvy8vLSgAEDVFpaqri4OL311lvm6729vbVq1SqNGjVKMTExatCggRISEvTiiy+aNW3atFFaWprGjx+vWbNmqWXLllq4cKHi4uLMmoceekhHjx7V1KlTVVBQoC5duig9Pb3KxeEAAODq5fJ9mtLT09WwYUPdeuutkr6/k/bbb7+tiIgIzZ07V9dcc02tNOrpuE8TAABXnlq9T9OECRPMexLt3r1bSUlJuueee5SXl6ekpKRL6xgAAMDDuXx6Li8vz7zI+h//+Ifuu+8+TZ8+XTt27NA999xT4w0CAAB4ApePNPn4+Oi7776TJH388cfq06ePpO9//oS7YgMAgLrK5SNNt956q5KSktSrVy9t3bpVy5YtkyR9+eWXatmyZY03CAAA4AlcPtI0Z84c1atXT3//+981b948XXvttZKk1atX6+67767xBgEAADyBy0eawsPDtWrVqirb33jjjRppCAAAwBO5fKQJAADgakRoAgAAsIDQBAAAYIGl0PT555+bvzcHAABwNbIUmm655RYdO3ZMknTdddfp22+/rdWmAAAAPI2l0BQUFKS8vDxJ0sGDBznqBAAArjqWbjkwYMAA3XHHHWrevLlsNpuioqLk7e1dbe3XX39dow0CAAB4AkuhacGCBerfv7+++uorPfXUU3rsscfUqFGj2u4NAADAY1i+uWXl3b6zsrI0duxYQhMAALiquHxH8EWLFpn//Z///EeS+M05AABQ57l8n6aKigq9+OKLCgwMVKtWrdSqVSsFBQXppZde4gJxAABQZ7l8pOm5557Tn//8Z82YMUO9evWSJH3yySd64YUXdPbsWb388ss13iQAAIC7uRya3n33XS1cuFD333+/ua1Tp0669tpr9eSTTxKaAABAneTy6bnjx4+rXbt2Vba3a9dOx48fr5GmAAAAPI3Loalz586aM2dOle1z5sxR586da6QpAAAAT+Py6blXXnlF8fHx+vjjjxUTEyNJyszM1KFDh/Thhx/WeIMAAACewOUjTXfccYe+/PJLPfDAAyouLlZxcbH69++v3Nxc3XbbbbXRIwAAgNu5fKRJklq0aMEF3wAA4Kri8pEmAACAqxGhCQAAwAJCEwAAgAUuhSbDMJSfn6+zZ8/WVj8AAAAeyeXQdMMNN+jQoUO11Q8AAIBHcik0eXl5qW3btvr2229rqx8AAACP5PI1TTNmzNCECROUk5NTG/0AAAB4JJfv0zRs2DB999136ty5s3x8fOTv7+80zu/PAQCAusjl0DRz5sxaaAMAAMCzuRyaEhISaqMPAAAAj3ZJ92k6cOCAJk+erMGDB6uoqEiStHr1au3Zs6dGmwMAAPAULoemjRs3qmPHjtqyZYs++OADnTp1SpK0a9cuPf/88zXeIAAAgCdw+fTcxIkT9fvf/15JSUlq1KiRuf3OO+/UnDlzarQ5XJrWE9Ms1x6cEV+LnQAAUHe4fKRp9+7deuCBB6psDw4O1rFjx2qkKQAAAE/jcmgKCgrSkSNHqmzfuXOnrr322hppCgAAwNO4HJoGDRqk5ORkFRQUyGazqaKiQp9++qmeeeYZDRs2rDZ6BAAAcDuXQ9P06dPVrl07hYWF6dSpU4qIiNDtt9+unj17avLkybXRIwAAgNu5fCG4j4+P3n77bU2ZMkU5OTk6deqUbrnlFrVt27Y2+gMAAPAILoemSuHh4QoLC5Mk2Wy2GmsIAADAE13SzS3//Oc/q0OHDvLz85Ofn586dOighQsX1nRvAAAAHsPlI01Tp07V66+/rjFjxigmJkaSlJmZqfHjxys/P18vvvhijTcJAADgbi6Hpnnz5untt9/W4MGDzW3333+/OnXqpDFjxhCaAABAneTy6blz584pKiqqyvbIyEidP3++RpoCAADwNC6HpqFDh2revHlVti9YsEBDhgypkaYAAAA8jaXTc0lJSeZ/22w2LVy4UB999JF69OghSdqyZYvy8/O5uSUAAKizLIWmnTt3Oj2PjIyUJB04cECS1LRpUzVt2lR79uyp4fYAAAA8g6XQtH79+truAwAAwKNd0n2aAAAArjYu33Lg7NmzevPNN7V+/XoVFRWpoqLCaXzHjh011hwAAICncDk0jRgxQh999JEGDhyo7t278xMqAADgquByaFq1apU+/PBD9erVqzb6AQAA8EguX9N07bXXqlGjRrXRCwAAgMdyOTS99tprSk5O1jfffFMb/QAAAHgkl0NTVFSUzp49q+uuu06NGjVS48aNnR6uSElJUbdu3dSoUSMFBwerX79+ys3Ndao5e/asEhMT1aRJEzVs2FADBgxQYWGhU01+fr7i4+MVEBCg4OBgTZgwocpPumzYsEFdu3aVr6+vbrjhBqWmplbpZ+7cuWrdurX8/PwUHR2trVu3urQ/AACg7nL5mqbBgwfrv//9r6ZPn66QkJCfdSH4xo0blZiYqG7duun8+fP63e9+pz59+uiLL75QgwYNJEnjx49XWlqali9frsDAQI0ePVr9+/fXp59+KkkqLy9XfHy8QkNDtXnzZh05ckTDhg1T/fr1NX36dElSXl6e4uPjNXLkSC1evFgZGRl69NFH1bx5c8XFxUmSli1bpqSkJM2fP1/R0dGaOXOm4uLilJubq+Dg4EveRwAAUDfYDMMwXHlBQECAMjMz1blz5xpv5ujRowoODtbGjRt1++23q6SkRM2aNdOSJUs0cOBASdK+ffvUvn17ZWZmqkePHlq9erXuvfdeHT58WCEhIZKk+fPnKzk5WUePHpWPj4+Sk5OVlpamnJwc870GDRqk4uJipaenS5Kio6PVrVs3zZkzR5JUUVGhsLAwjRkzRhMnTrxo7w6HQ4GBgSopKZHdbq/ppVHriWk1PqckHZwRXyvzAgBwJXDl89vl03Pt2rXTmTNnLrm5n1JSUiJJ5mm+rKwsnTt3TrGxsU7vHx4erszMTElSZmamOnbsaAYmSYqLi5PD4TB/1iUzM9NpjsqayjnKysqUlZXlVOPl5aXY2FizBgAAXN1cDk0zZszQ008/rQ0bNujbb7+Vw+FwelyqiooKjRs3Tr169VKHDh0kSQUFBfLx8VFQUJBTbUhIiAoKCsyaCwNT5Xjl2E/VOBwOnTlzRseOHVN5eXm1NZVz/FBpaWmN7TsAAPB8Ll/TdPfdd0uSevfu7bTdMAzZbDaVl5dfUiOJiYnKycnRJ598ckmvv9xSUlI0bdo0d7cBAAAuE5dDU238eO/o0aO1atUqbdq0SS1btjS3h4aGqqysTMXFxU5HmwoLCxUaGmrW/PBbbpXfrruw5offuCssLJTdbpe/v7+8vb3l7e1dbU3lHD80adIkJSUlmc8dDofCwsJc3HMAAHClcDk03XHHHTX25oZhaMyYMVqxYoU2bNigNm3aOI1HRkaqfv36ysjI0IABAyRJubm5ys/PV0xMjCQpJiZGL7/8soqKisxvua1du1Z2u10RERFmzYcffug099q1a805fHx8FBkZqYyMDPXr10/S96cLMzIyNHr06Gp79/X1la+vb80sBAAA8Hguh6ZNmzb95Pjtt99uea7ExEQtWbJE//znP9WoUSPz+qHAwED5+/srMDBQI0aMUFJSkho3biy73a4xY8YoJiZGPXr0kCT16dNHERERGjp0qF555RUVFBRo8uTJSkxMNEPNyJEjNWfOHD377LN65JFHtG7dOr3//vtKS/vfN9KSkpKUkJCgqKgode/eXTNnztTp06c1fPhwV5cIAADUQS6Hpl/84hdVtl14ryZXrmmaN29etXMuWrRIDz/8sCTpjTfekJeXlwYMGKDS0lLFxcXprbfeMmu9vb21atUqjRo1SjExMWrQoIESEhL04osvmjVt2rRRWlqaxo8fr1mzZqlly5ZauHCheY8mSXrooYd09OhRTZ06VQUFBerSpYvS09OrXBwOAACuTi7fp6nytgCVzp07p507d2rKlCl6+eWXq1wgfrXgPk0AAFx5XPn8dvlIU2BgYJVtd911l3x8fJSUlKSsrCxXpwQAAPB4Lt+n6ceEhIRU+d04AACAusLlI02ff/6503PDMHTkyBHNmDFDXbp0qam+AAAAPIrLoalLly6y2Wz64aVQPXr00DvvvFNjjQEAAHgSl0NTXl6e03MvLy81a9ZMfn5+NdYUAACAp3E5NLVq1ao2+gAAAPBoLocmScrIyFBGRoaKiopUUVHhNMYpOgAAUBe5HJqmTZumF198UVFRUWrevLnTjS0BAADqKpdD0/z585WamqqhQ4fWRj8AAAAeyeX7NJWVlalnz5610QsAAIDHcjk0Pfroo1qyZElt9AIAAOCxXD49d/bsWS1YsEAff/yxOnXqpPr16zuNv/766zXWHAAAgKe4pDuCV975Oycnx2mMi8IBAEBd5XJoWr9+fW30AQAA4NFq7Ad7AQAA6jJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFrg1NG3atEn33XefWrRoIZvNppUrVzqNG4ahqVOnqnnz5vL391dsbKz279/vVHP8+HENGTJEdrtdQUFBGjFihE6dOuVU8/nnn+u2226Tn5+fwsLC9Morr1TpZfny5WrXrp38/PzUsWNHffjhhzW+vwAA4Mrl1tB0+vRpde7cWXPnzq12/JVXXtHs2bM1f/58bdmyRQ0aNFBcXJzOnj1r1gwZMkR79uzR2rVrtWrVKm3atEmPP/64Oe5wONSnTx+1atVKWVlZevXVV/XCCy9owYIFZs3mzZs1ePBgjRgxQjt37lS/fv3Ur18/5eTk1N7OAwCAK4rNMAzD3U1Iks1m04oVK9SvXz9J3x9latGihZ5++mk988wzkqSSkhKFhIQoNTVVgwYN0t69exUREaFt27YpKipKkpSenq577rlH//nPf9SiRQvNmzdPzz33nAoKCuTj4yNJmjhxolauXKl9+/ZJkh566CGdPn1aq1atMvvp0aOHunTpovnz51vq3+FwKDAwUCUlJbLb7TW1LKbWE9NqfE5JOjgjvlbmBQDgSuDK57fHXtOUl5engoICxcbGmtsCAwMVHR2tzMxMSVJmZqaCgoLMwCRJsbGx8vLy0pYtW8ya22+/3QxMkhQXF6fc3FydOHHCrLnwfSprKt+nOqWlpXI4HE4PAABQd3lsaCooKJAkhYSEOG0PCQkxxwoKChQcHOw0Xq9ePTVu3Nippro5LnyPH6upHK9OSkqKAgMDzUdYWJiruwgAAK4gHhuaPN2kSZNUUlJiPg4dOuTulgAAQC3y2NAUGhoqSSosLHTaXlhYaI6FhoaqqKjIafz8+fM6fvy4U011c1z4Hj9WUzleHV9fX9ntdqcHAACouzw2NLVp00ahoaHKyMgwtzkcDm3ZskUxMTGSpJiYGBUXFysrK8usWbdunSoqKhQdHW3WbNq0SefOnTNr1q5dq5tuuknXXHONWXPh+1TWVL4PAACAW0PTqVOnlJ2drezsbEnfX/ydnZ2t/Px82Ww2jRs3Tr///e/1r3/9S7t379awYcPUokUL8xt27du31913363HHntMW7du1aeffqrRo0dr0KBBatGihSTpN7/5jXx8fDRixAjt2bNHy5Yt06xZs5SUlGT2MXbsWKWnp+u1117Tvn379MILL2j79u0aPXr05V4SAADgoeq58823b9+uX/7yl+bzyiCTkJCg1NRUPfvsszp9+rQef/xxFRcX69Zbb1V6err8/PzM1yxevFijR49W79695eXlpQEDBmj27NnmeGBgoD766CMlJiYqMjJSTZs21dSpU53u5dSzZ08tWbJEkydP1u9+9zu1bdtWK1euVIcOHS7DKgAAgCuBx9yn6UrHfZoAALjy1In7NAEAAHgSQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABW797Tm4n6s/z8LPrgAArlYcaQIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFhAaAIAALCA0AQAAGABoQkAAMACQhMAAIAFhCYAAAALCE0AAAAW1HN3A7iytJ6YZrn24Iz4WuwEAIDLiyNNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBAAAYAGhCQAAwAJCEwAAgAWEJgAAAAsITQAAABYQmgAAACwgNAEAAFjAb8+h1vA7dQCAuoQjTQAAABYQmgAAACwgNAEAAFhAaPqBuXPnqnXr1vLz81N0dLS2bt3q7pYAAIAH4ELwCyxbtkxJSUmaP3++oqOjNXPmTMXFxSk3N1fBwcHubq9O46JxAICn40jTBV5//XU99thjGj58uCIiIjR//nwFBATonXfecXdrAADAzTjS9H/KysqUlZWlSZMmmdu8vLwUGxurzMxMN3aGH3LlqJSrOIoFAPgxhKb/c+zYMZWXlyskJMRpe0hIiPbt21elvrS0VKWlpebzkpISSZLD4aiV/ipKv6uVeeEsfPxyd7cgScqZFufuFgDgqlD5uW0YxkVrCU2XKCUlRdOmTauyPSwszA3doK4JnOnuDgDg6nLy5EkFBgb+ZA2h6f80bdpU3t7eKiwsdNpeWFio0NDQKvWTJk1SUlKS+byiokLHjx9XkyZNZLPZaqwvh8OhsLAwHTp0SHa7vcbmrUtYo4tjjS6ONbKGdbo41ujiPGmNDMPQyZMn1aJFi4vWEpr+j4+PjyIjI5WRkaF+/fpJ+j4IZWRkaPTo0VXqfX195evr67QtKCio1vqz2+1u/z+Wp2ONLo41ujjWyBrW6eJYo4vzlDW62BGmSoSmCyQlJSkhIUFRUVHq3r27Zs6cqdOnT2v48OHubg0AALgZoekCDz30kI4ePaqpU6eqoKBAXbp0UXp6epWLwwEAwNWH0PQDo0ePrvZ0nLv4+vrq+eefr3IqEP/DGl0ca3RxrJE1rNPFsUYXd6Wukc2w8h07AACAqxx3BAcAALCA0AQAAGABoQkAAMACQhMAAIAFhCYPNnfuXLVu3Vp+fn6Kjo7W1q1b3d3SZZOSkqJu3bqpUaNGCg4OVr9+/ZSbm+tUc/bsWSUmJqpJkyZq2LChBgwYUOWO7vn5+YqPj1dAQICCg4M1YcIEnT9//nLuymUzY8YM2Ww2jRs3ztzGGkn//e9/9dvf/lZNmjSRv7+/OnbsqO3bt5vjhmFo6tSpat68ufz9/RUbG6v9+/c7zXH8+HENGTJEdrtdQUFBGjFihE6dOnW5d6VWlJeXa8qUKWrTpo38/f11/fXX66WXXnL6Ha6rcY02bdqk++67Ty1atJDNZtPKlSudxmtqTT7//HPddttt8vPzU1hYmF555ZXa3rUa81NrdO7cOSUnJ6tjx45q0KCBWrRooWHDhunw4cNOc1xxa2TAIy1dutTw8fEx3nnnHWPPnj3GY489ZgQFBRmFhYXubu2yiIuLMxYtWmTk5OQY2dnZxj333GOEh4cbp06dMmtGjhxphIWFGRkZGcb27duNHj16GD179jTHz58/b3To0MGIjY01du7caXz44YdG06ZNjUmTJrljl2rV1q1bjdatWxudOnUyxo4da26/2tfo+PHjRqtWrYyHH37Y2LJli/H1118ba9asMb766iuzZsaMGUZgYKCxcuVKY9euXcb9999vtGnTxjhz5oxZc/fddxudO3c2PvvsM+P//b//Z9xwww3G4MGD3bFLNe7ll182mjRpYqxatcrIy8szli9fbjRs2NCYNWuWWXM1rtGHH35oPPfcc8YHH3xgSDJWrFjhNF4Ta1JSUmKEhIQYQ4YMMXJycoz33nvP8Pf3N/70pz9drt38WX5qjYqLi43Y2Fhj2bJlxr59+4zMzEyje/fuRmRkpNMcV9oaEZo8VPfu3Y3ExETzeXl5udGiRQsjJSXFjV25T1FRkSHJ2Lhxo2EY3/9B1q9f31i+fLlZs3fvXkOSkZmZaRjG93/QXl5eRkFBgVkzb948w263G6WlpZd3B2rRyZMnjbZt2xpr16417rjjDjM0sUaGkZycbNx6660/Ol5RUWGEhoYar776qrmtuLjY8PX1Nd577z3DMAzjiy++MCQZ27ZtM2tWr15t2Gw247///W/tNX+ZxMfHG4888ojTtv79+xtDhgwxDIM1MgyjSiCoqTV56623jGuuucbpby05Odm46aabanmPal51wfKHtm7dakgyvvnmG8Mwrsw14vScByorK1NWVpZiY2PNbV5eXoqNjVVmZqYbO3OfkpISSVLjxo0lSVlZWTp37pzTGrVr107h4eHmGmVmZqpjx45Od3SPi4uTw+HQnj17LmP3tSsxMVHx8fFOayGxRpL0r3/9S1FRUfr1r3+t4OBg3XLLLXr77bfN8by8PBUUFDitUWBgoKKjo53WKCgoSFFRUWZNbGysvLy8tGXLlsu3M7WkZ8+eysjI0JdffilJ2rVrlz755BP17dtXEmtUnZpak8zMTN1+++3y8fExa+Li4pSbm6sTJ05cpr25fEpKSmSz2czfab0S14g7gnugY8eOqby8vMrPt4SEhGjfvn1u6sp9KioqNG7cOPXq1UsdOnSQJBUUFMjHx6fKjySHhISooKDArKluDSvH6oKlS5dqx44d2rZtW5Ux1kj6+uuvNW/ePCUlJel3v/udtm3bpqeeeko+Pj5KSEgw97G6NbhwjYKDg53G69Wrp8aNG9eJNZo4caIcDofatWsnb29vlZeX6+WXX9aQIUMkiTWqRk2tSUFBgdq0aVNljsqxa665plb6d4ezZ88qOTlZgwcPNn+g90pcI0ITPF5iYqJycnL0ySefuLsVj3Lo0CGNHTtWa9eulZ+fn7vb8UgVFRWKiorS9OnTJUm33HKLcnJyNH/+fCUkJLi5O8/w/vvva/HixVqyZIluvvlmZWdna9y4cWrRogVrhBpx7tw5PfjggzIMQ/PmzXN3Oz8Lp+c8UNOmTeXt7V3lW06FhYUKDQ11U1fuMXr0aK1atUrr169Xy5Ytze2hoaEqKytTcXGxU/2FaxQaGlrtGlaOXemysrJUVFSkrl27ql69eqpXr542btyo2bNnq169egoJCbnq16h58+aKiIhw2ta+fXvl5+dL+t8+/tTfWmhoqIqKipzGz58/r+PHj9eJNZowYYImTpyoQYMGqWPHjho6dKjGjx+vlJQUSaxRdWpqTer635/0v8D0zTffaO3ateZRJunKXCNCkwfy8fFRZGSkMjIyzG0VFRXKyMhQTEyMGzu7fAzD0OjRo7VixQqtW7euyuHZyMhI1a9f32mNcnNzlZ+fb65RTEyMdu/e7fRHWflH+8MP0itR7969tXv3bmVnZ5uPqKgoDRkyxPzvq32NevXqVeVWFV9++aVatWolSWrTpo1CQ0Od1sjhcGjLli1Oa1RcXKysrCyzZt26daqoqFB0dPRl2Iva9d1338nLy/mjwNvbWxUVFZJYo+rU1JrExMRo06ZNOnfunFmzdu1a3XTTTXXi1FxlYNq/f78+/vhjNWnSxGn8ilwjt1x+jotaunSp4evra6SmphpffPGF8fjjjxtBQUFO33Kqy0aNGmUEBgYaGzZsMI4cOWI+vvvuO7Nm5MiRRnh4uLFu3Tpj+/btRkxMjBETE2OOV36dvk+fPkZ2draRnp5uNGvWrM58nb46F357zjBYo61btxr16tUzXn75ZWP//v3G4sWLjYCAAONvf/ubWTNjxgwjKCjI+Oc//2l8/vnnxq9+9atqvzp+yy23GFu2bDE++eQTo23btlf01+kvlJCQYFx77bXmLQc++OADo2nTpsazzz5r1lyNa3Ty5Elj586dxs6dOw1Jxuuvv27s3LnT/OZXTaxJcXGxERISYgwdOtTIyckxli5dagQEBFwxtxz4qTUqKysz7r//fqNly5ZGdna207/jF34T7kpbI0KTB3vzzTeN8PBww8fHx+jevbvx2Wefubuly0ZStY9FixaZNWfOnDGefPJJ45prrjECAgKMBx54wDhy5IjTPAcPHjT69u1r+Pv7G02bNjWefvpp49y5c5d5by6fH4Ym1sgw/v3vfxsdOnQwfH19jXbt2hkLFixwGq+oqDCmTJlihISEGL6+vkbv3r2N3Nxcp5pvv/3WGDx4sNGwYUPDbrcbw4cPN06ePHk5d6PWOBwOY+zYsUZ4eLjh5+dnXHfddcZzzz3n9MF2Na7R+vXrq/03KCEhwTCMmluTXbt2Gbfeeqvh6+trXHvttcaMGTMu1y7+bD+1Rnl5eT/67/j69evNOa60NbIZxgW3fQUAAEC1uKYJAADAAkITAACABYQmAAAACwhNAAAAFhCaAAAALCA0AQAAWEBoAgAAsIDQBMBlv/jFLzRu3Dh3tyFJ2rBhg2w2W5Xf2KsJL7zwgkJCQmSz2bRy5coan7+2HDx4UDabTdnZ2e5uBahTCE0ArhiXM6zt3btX06ZN05/+9CcdOXJEffv2vSzvC8Bz1XN3AwDgiQ4cOCBJ+tWvfiWbzebmbgB4Ao40AfjZSktL9cwzz+jaa69VgwYNFB0drQ0bNpjjqampCgoK0po1a9S+fXs1bNhQd999t44cOWLWnD9/Xk899ZSCgoLUpEkTJScnKyEhQf369ZMkPfzww9q4caNmzZolm80mm82mgwcPmq/PyspSVFSUAgIC1LNnT+Xm5v5kz7t379add94pf39/NWnSRI8//rhOnTol6fvTcvfdd58kycvL60dD04kTJzRkyBA1a9ZM/v7+atu2rRYtWmSOJycn68Ybb1RAQICuu+46TZkyxenX2l944QV16dJF77zzjsLDw9WwYUM9+eSTKi8v1yuvvKLQ0FAFBwfr5Zdfdnpfm82mefPmqW/fvvL399d1112nv//97z+5vzk5Oerbt68aNmyokJAQDR06VMeOHTPH//73v6tjx47mesTGxur06dM/OSdwtSE0AfjZRo8erczMTC1dulSff/65fv3rX+vuu+/W/v37zZrvvvtOf/zjH/XXv/5VmzZtUn5+vp555hlz/A9/+IMWL16sRYsW6dNPP5XD4XC6jmjWrFmKiYnRY489piNHjujIkSMKCwszx5977jm99tpr2r59u+rVq6dHHnnkR/s9ffq04uLidM0112jbtm1avny5Pv74Y40ePVqS9Mwzz5jhp/K9qjNlyhR98cUXWr16tfbu3at58+apadOm5nijRo2UmpqqL774QrNmzdLbb7+tN954w2mOAwcOaPXq1UpPT9d7772nP//5z4qPj9d//vMfbdy4UX/4wx80efJkbdmypcp7DxgwQLt27dKQIUM0aNAg7d27t9o+i4uLdeedd+qWW27R9u3blZ6ersLCQj344IPmPg4ePFiPPPKI9u7dqw0bNqh///7ip0mBH3DbTwUDuGLdcccdxtixYw3DMIxvvvnG8Pb2Nv773/861fTu3duYNGmSYRiGsWjRIkOS8dVXX5njc+fONUJCQsznISEhxquvvmo+P3/+vBEeHm786le/qvZ9K1X+0vrHH39sbktLSzMkGWfOnKm2/wULFhjXXHONcerUKafXeHl5GQUFBYZhGMaKFSuMi/0Ted999xnDhw//yZoLvfrqq0ZkZKT5/PnnnzcCAgIMh8NhbouLizNat25tlJeXm9tuuukmIyUlxXwuyRg5cqTT3NHR0caoUaMMwzDMX5jfuXOnYRiG8dJLLxl9+vRxqj906JAhycjNzTWysrIMScbBgwct7wtwNeKaJgA/y+7du1VeXq4bb7zRaXtpaamaNGliPg8ICND1119vPm/evLmKiookSSUlJSosLFT37t3NcW9vb0VGRqqiosJSH506dXKaW5KKiooUHh5epXbv3r3q3LmzGjRoYG7r1auXKioqlJubq5CQEEvvOWrUKA0YMEA7duxQnz591K9fP/Xs2dMcX7ZsmWbPnq0DBw7o1KlTOn/+vOx2u9McrVu3VqNGjcznISEh8vb2lpeXl9O2yrWqFBMTU+X5j31bbteuXVq/fr0aNmxYZezAgQPq06ePevfurY4dOyouLk59+vTRwIEDdc0111haB+BqQWgC8LOcOnVK3t7eysrKkre3t9PYhR/S9evXdxqz2Ww1evrnwvkrr0GyGrguVd++ffXNN9/oww8/1Nq1a9W7d28lJibqj3/8ozIzMzVkyBBNmzZNcXFxCgwM1NKlS/Xaa6/9aN+VvVe37efsy6lTp3TffffpD3/4Q5Wx5s2by9vbW2vXrtXmzZv10Ucf6c0339Rzzz2nLVu2qE2bNpf8vkBdwzVNAH6WW265ReXl5SoqKtINN9zg9AgNDbU0R2BgoEJCQrRt2zZzW3l5uXbs2OFU5+Pjo/Ly8p/dc/v27bVr1y6nC50//fRTeXl56aabbnJprmbNmikhIUF/+9vfNHPmTC1YsECStHnzZrVq1UrPPfecoqKi1LZtW33zzTc/u/dKn332WZXn7du3r7a2a9eu2rNnj1q3bl3lf6PKo202m029evXStGnTtHPnTvn4+GjFihU11i9QFxCaAPwsN954o4YMGaJhw4bpgw8+UF5enrZu3aqUlBSlpaVZnmfMmDFKSUnRP//5T+Xm5mrs2LE6ceKE0zfXWrdurS1btujgwYM6duzYJR99GTJkiPz8/JSQkKCcnBytX79eY8aM0dChQy2fmpOkqVOn6p///Ke++uor7dmzR6tWrTKDS9u2bZWfn6+lS5fqwIEDmj17do2GkOXLl+udd97Rl19+qeeff15bt241L2T/ocTERB0/flyDBw/Wtm3bdODAAa1Zs0bDhw9XeXm5tmzZounTp2v79u3Kz8/XBx98oKNHj/5oCAOuVoQmAD/bokWLNGzYMD399NO66aab1K9fP23btq3a64l+THJysgYPHqxhw4YpJiZGDRs2VFxcnPz8/MyaZ555Rt7e3oqIiFCzZs2Un59/Sf0GBARozZo1On78uLp166aBAweqd+/emjNnjkvz+Pj4aNKkSerUqZNuv/12eXt7a+nSpZKk+++/X+PHj9fo0aPVpUsXbd68WVOmTLmkfqszbdo0LV26VJ06ddJf/vIXvffee4qIiKi2tkWLFvr0009VXl6uPn36qGPHjho3bpyCgoLk5eUlu92uTZs26Z577tGNN96oyZMn67XXXuOGnsAP2IyavKgAAGpIRUWF2rdvrwcffFAvvfSSu9vxKDabTStWrDDvYQXg8uBCcAAe4ZtvvtFHH32kO+64Q6WlpZozZ47y8vL0m9/8xt2tAYAkTs8B8BBeXl5KTU1Vt27d1KtXL+3evVsff/wx19UA8BicngMAALCAI00AAAAWEJoAAAAsIDQBAABYQGgCAACwgNAEAABgAaEJAADAAkITAACABYQmAAAACwhNAAAAFvx/mi9eYyuksfkAAAAASUVORK5CYII="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:45:59.532373Z",
     "start_time": "2023-09-13T16:45:58.386744Z"
    }
   },
   "id": "b0ba9f55d3f34c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "위의 그래프처럼, 많은 양의 데이터를 다룰 때는 데이터를 시각화하여 보는 것이 도움이 돼요. 위에서부터 차례대로 그래프는 각각 실제 텍스트와 요약의 길이 분포, 실제 텍스트 샘플 길이별 개수, 요약본 샘플 길이별 개수를 나타내고 있어요.\n",
    "\n",
    "Text의 경우 최소 길이가 2, 최대 길이가 1,235로 그 차이가 굉장히 크죠. 하지만 평균 길이는 38로 시각화된 그래프로 봤을 때는 대체적으로는 100 내외의 길이를 가진다는 것을 확인할 수 있어요.\n",
    "\n",
    "Summary의 경우 최소 길이가 1, 최대 길이가 28, 그리고 평균 길이가 4로 Text에 비해 상대적으로 길이가 매우 짧아요. 그래프로 봤을 때에도 대체적으로 10이하의 길이를 가지고 있네요.\n",
    "\n",
    "이로부터 Text의 최대 길이와 Summary의 적절한 최대 길이를 임의로 정해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5410138cdebead5"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:01.607010Z",
     "start_time": "2023-09-13T16:46:01.566423Z"
    }
   },
   "id": "46864bf6aecd456"
  },
  {
   "cell_type": "markdown",
   "source": [
    "각각 50과 8로 정했는데 이 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고 포함할 수 있는지 통계로 확인하는 편이 객관적으로 길이를 결정하는 데 도움이 될거예요. 훈련 데이터와 샘플의 길이를 입력하면, 데이터의 몇 %가 해당하는지 계산하는 함수를 만들어서 좀 더 정확하게 판단해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c18b4efcce9a6d7a"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:03.651470Z",
     "start_time": "2023-09-13T16:46:03.585817Z"
    }
   },
   "id": "e1d4a80450492d84"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이렇게 만든 함수를 Text와 Summary에 적용해 우리가 결정한 임의의 길이가 몇%의 샘플까지 포함하는지 볼 수 있겠죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d81d3d5c1ba9f978"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:05.281389Z",
     "start_time": "2023-09-13T16:46:05.134048Z"
    }
   },
   "id": "c122798e4b3fdff"
  },
  {
   "cell_type": "markdown",
   "source": [
    "각각 50과 8로 패딩을 하게 되면 해당 길이보다 긴 샘플들은 내용이 잘리게 되는데, Text 열의 경우에는 약 23%의 샘플들이 내용이 망가지게 된다고 하네요.\n",
    "\n",
    "우리는 정해진 길이에 맞춰 자르는 것이 아니라, 정해진 길이보다 길면 제외하는 방법으로 데이터를 정제할게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9dd47dc183c4319"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Text와 Summary를 담고 있는 data 데이터프레임을 위에서 임의로 정의한 text_max_len과 summary_max_len의 길이보다 큰 샘플을 제외하는 코드를 작성하세요.\n",
    "(힌트 : apply 함수와 lamda식을 사용)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34162fd46de4367f"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "#Text와 Summary를 담고 있는 data 데이터프레임을 위에서 임의로 정의한 text_max_len과 summary_max_len의 길이보다 큰 샘플을 제외하는 코드를 작성하세요.(힌트 : apply 함수와 lamda식을 사용)\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "\n",
    "\n",
    "print('전체 샘플수 :', (len(data)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:07.506451Z",
     "start_time": "2023-09-13T16:46:07.178580Z"
    }
   },
   "id": "aa944fba148dbfb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 시작 토큰과 종료 토큰 추가하기\n",
    "\n",
    "앞서 시작 토큰과 종료 토큰에 대해서 언급했던 것을 기억하시나요? 디코더는 시작 토큰을 입력받아 문장을 생성하기 시작하고, 종료 토큰을 예측한 순간에 문장 생성을 멈추는 거였죠.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-21-4.png)\n",
    "\n",
    "[시작 토큰 SOS와 종료 토큰 EOS는 각각 start of a sequence와 end of a sequence를 나타낸다]\n",
    "https://arxiv.org/pdf/1812.02303.pdf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab2b332ccda934e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "seq2seq 훈련을 위해서는 디코더의 입력과 레이블에 시작 토큰과 종료 토큰을 추가할 필요가 있어요. 이번 실습에서는 시작 토큰은 sostoken, 종료 토큰은 eostoken이라 임의로 명명하고 앞, 뒤로 추가할 거예요. 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input, 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정했어요. 두 개의 문장 모두 Summary 열로부터 만들 거예요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b63973c679bf5116"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                Text                Summary  \\\n0  bought several vitality canned dog food produc...  good quality dog food   \n1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n2  confection around centuries light pillowy citr...    delight says it all   \n3  looking secret ingredient robitussin believe f...         cough medicine   \n4  great taffy great price wide assortment yummy ...            great taffy   \n\n                    decoder_input                  decoder_target  \n0  sostoken good quality dog food  good quality dog food eostoken  \n1      sostoken not as advertised      not as advertised eostoken  \n2    sostoken delight says it all    delight says it all eostoken  \n3         sostoken cough medicine         cough medicine eostoken  \n4            sostoken great taffy            great taffy eostoken  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Summary</th>\n      <th>decoder_input</th>\n      <th>decoder_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bought several vitality canned dog food produc...</td>\n      <td>good quality dog food</td>\n      <td>sostoken good quality dog food</td>\n      <td>good quality dog food eostoken</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>product arrived labeled jumbo salted peanuts p...</td>\n      <td>not as advertised</td>\n      <td>sostoken not as advertised</td>\n      <td>not as advertised eostoken</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>confection around centuries light pillowy citr...</td>\n      <td>delight says it all</td>\n      <td>sostoken delight says it all</td>\n      <td>delight says it all eostoken</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>looking secret ingredient robitussin believe f...</td>\n      <td>cough medicine</td>\n      <td>sostoken cough medicine</td>\n      <td>cough medicine eostoken</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>great taffy great price wide assortment yummy ...</td>\n      <td>great taffy</td>\n      <td>sostoken great taffy</td>\n      <td>great taffy eostoken</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:09.430924Z",
     "start_time": "2023-09-13T16:46:09.359430Z"
    }
   },
   "id": "9f196cd217c8bc57"
  },
  {
   "cell_type": "markdown",
   "source": [
    "앞뒤로 토큰이 잘 붙었죠? 인코더의 입력, 디코더의 입력과 레이블을 각각 다시 Numpy 타입으로 저장해 줄게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1647cbbedfe5bf9"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:10.978662Z",
     "start_time": "2023-09-13T16:46:10.915787Z"
    }
   },
   "id": "36ce5db8d6253426"
  },
  {
   "cell_type": "markdown",
   "source": [
    "제 훈련 데이터와 테스트 데이터를 분리할거에요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터를 분리하는 방법은 분리 패키지를 사용하는 방법, 또는 직접 코딩을 통해서 분리하는 방법 등 여러 가지 방법이 있을 텐데 여기서는 직접 해볼게요. 우선, encoder_input과 크기와 형태가 같은 순서가 섞인 정수 시퀀스를 만들어줄게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af1853dac31070fe"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19566 11610 30584 ...  8137 34787 31347]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:12.562881Z",
     "start_time": "2023-09-13T16:46:12.494334Z"
    }
   },
   "id": "1606cd8bd5a07a83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이 정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플이 되겠죠."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12216a057fe1870"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:14.200472Z",
     "start_time": "2023-09-13T16:46:14.139037Z"
    }
   },
   "id": "6b4c26547d57b467"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리해 줄게요. 전체 데이터의 크기에서 0.2를 곱해서 테스트 데이터의 크기를 정의해 줄게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f888690f2f0a3962"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:15.996478Z",
     "start_time": "2023-09-13T16:46:15.936847Z"
    }
   },
   "id": "d05fe29cf63fe2c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이렇게 정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분할게요. :표시의 위치에 주의해 주세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eccbdf02bc6c66a9"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:17.533189Z",
     "start_time": "2023-09-13T16:46:17.472584Z"
    }
   },
   "id": "f59d2f42bd108429"
  },
  {
   "cell_type": "markdown",
   "source": [
    "훈련 데이터와 테스트 데이터가 각각 52,655개와 13,163개로 잘 분리된 것을 볼 수 있어요!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ef3e9ccb6355c54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-7. 데이터 전처리하기 (3) 정수 인코딩\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "470556b81b83066d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 단어 집합(vocabulary) 만들기 및 정수 인코딩\n",
    "\n",
    "이제 기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터의 단어들을 모두 정수로 바꾸어 주어야 해요. 이를 위해서는 각 단어에 고유한 정수를 맵핑하는 작업이 필요해요. 이 과정을 단어 집합(vocabulary) 을 만든다고 표현해요. 훈련 데이터에 대해서 단어 집합을 만들어볼게요. 우선, 원문에 해당되는 encoder_input_train에 대해서 단어 집합을 만들게요.\n",
    "\n",
    "Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "693b62e58219eb71"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:22.223358Z",
     "start_time": "2023-09-13T16:46:21.470802Z"
    }
   },
   "id": "b2af99c53d154982"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. 현재 생성된 단어 집합은 src_tokenizer.word_index에 저장되어 있어요. 그런데 우리는 이렇게 만든 단어 집합에 있는 모든 단어를 사용하는 것이 아니라, 빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행하려고 해요.\n",
    "\n",
    "등장 빈도수가 7회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요.\n",
    "\n",
    "src_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻을 수 있어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27b1674ebde638a0"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31860\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23605\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8255\n",
      "단어 집합에서 희귀 단어의 비율: 74.08976773383553\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.374280692613025\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:23.096417Z",
     "start_time": "2023-09-13T16:46:23.033845Z"
    }
   },
   "id": "741e5cff77bcac99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "encoder_input_train에는 3만여 개의 단어가 있네요. 그 아래의 통계 정보들을 해석해볼까요?\n",
    "\n",
    "등장 빈도가 threshold 값인 7회 미만, 즉 6회 이하인 단어들은 단어 집합에서 무려 70% 이상을 차지하네요. 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 3.39%밖에 되지 않아요.\n",
    "\n",
    "그래서 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하고자 합니다. 위에서 이를 제외한 단어 집합의 크기를 8천여 개로 계산했는데, 이와 비슷한 값으로 어림잡아 단어 집합의 크기를 8,000으로 제한해볼게요. 토크나이저를 정의할 때 num_words의 값을 정해주면, 단어 집합의 크기를 제한할 수 있어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59dfcd9a7d50b8b4"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:25.329682Z",
     "start_time": "2023-09-13T16:46:24.582555Z"
    }
   },
   "id": "85e0f0e5671ff70a"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:27.066046Z",
     "start_time": "2023-09-13T16:46:26.324349Z"
    }
   },
   "id": "38a4434cc0495213"
  },
  {
   "cell_type": "markdown",
   "source": [
    "texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행해요. 현재 단어 집합의 크기를 8,000으로 제한했으니까 이제 8,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않아요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f82833ba28499e51"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[58, 1136, 3976, 4757, 1048, 1804, 492, 1689, 4493, 234, 357, 58, 4494, 6, 910, 1021, 1689, 6444, 6155, 6156, 49, 13, 56, 1292, 118, 443, 974, 1008, 1185, 7, 192, 475, 220, 560, 1689, 6794, 351], [824, 258, 2333, 9, 1, 62, 3733, 12, 30, 174, 1, 2918, 84, 258, 113, 166, 145, 3600, 1877, 464, 422, 145, 166, 1355, 4079, 1376, 145, 420, 623, 263], [237, 370, 25, 649, 226, 47, 863, 359, 3, 3601, 466, 152]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:28.364142Z",
     "start_time": "2023-09-13T16:46:27.749635Z"
    }
   },
   "id": "5729f4934ccbd76e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 더 이상 텍스트 데이터가 아니라 정수가 나오고 있어요.\n",
    "\n",
    "Summary 데이터에 대해서도 동일한 작업을 수행할게요. 케라스의 토크나이저를 사용하여 decoder_input_train을 입력으로 전체 단어 집합과 각 단어에 대한 빈도수를 계산해요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "861b451f0a7f2300"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:30.511637Z",
     "start_time": "2023-09-13T16:46:30.102947Z"
    }
   },
   "id": "99d5a82fe8574b96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었어요. 이는 tar_tokenizer.word_index에 저장되어 있어요. tar_tokenizer.word_counts.items()에는 단어와 각 단어의 등장 빈도수가 저장돼 있는데, 이를 통해서 통계적인 정보를 얻어서, 등장 빈도수가 6회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46a5004df58b56ed"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10443\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8048\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2395\n",
      "단어 집합에서 희귀 단어의 비율: 77.0659772096141\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.845637294993758\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:31.777615Z",
     "start_time": "2023-09-13T16:46:31.678751Z"
    }
   },
   "id": "4490cd39d179fb0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "등장 빈도가 5회 이하인 단어들은 단어 집합에서 약 77%를 차지하고 있네요. 하지만 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 5.87%밖에 되지 않아요. 아까 했던 것과 동일하게 이 단어들은 모두 제거할게요. 어림잡아 2,000을 단어 집합의 크기로 제한할게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8db7332dc43e0ae"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 1955, 290, 245], [1, 10, 5, 13, 59, 1557, 131], [1, 29, 9, 185, 264], [1, 59, 626, 395, 10, 5, 139, 9, 174], [1, 137, 149, 104, 51, 62, 15]]\n",
      "target\n",
      "decoder  [[1955, 290, 245, 2], [10, 5, 13, 59, 1557, 131, 2], [29, 9, 185, 264, 2], [59, 626, 395, 10, 5, 139, 9, 174, 2], [137, 149, 104, 51, 62, 15, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:35.065999Z",
     "start_time": "2023-09-13T16:46:33.754972Z"
    }
   },
   "id": "704f8f8896dbf3eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "정상적으로 정수 인코딩 작업이 끝났어요. 현재 decoder_input_train과 decoder_target_train에는 더 이상 숫자 2,000이 넘는 숫자들은 존재하지 않아요. 그런데 다음 작업인 패딩 하기로 넘어가기 전에 한 가지 점검해야 할 것이 있어요.\n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있어요. 이 현상은 길이가 상대적으로 길었던 원문(Text)의 경우에는 문제가 별로 없겠지만, 애초에 평균 길이가 4밖에 되지 않았던 요약문(Summary)의 경우에는 이 현상이 굉장히 두드러졌을 가능성이 높겠죠.\n",
    "\n",
    "요약문에서 길이가 0이 된 샘플들의 인덱스를 받아와볼게요. 여기서 주의할 점은 요약문인 decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않아요. 그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 거예요. 길이 0이 된 decoder_input에는 sostoken, decoder_target에는 eostoken만 남아 있을 테니까요.\n",
    "\n",
    "훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 각각 drop_train과 drop_test에 라는 변수에 저장해볼게요. 이 샘플들은 모두 삭제할 거예요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36c6efb3a274612b"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1248\n",
      "삭제할 테스트 데이터의 개수 : 356\n",
      "훈련 데이터의 개수 : 51407\n",
      "훈련 레이블의 개수 : 51407\n",
      "테스트 데이터의 개수 : 12807\n",
      "테스트 레이블의 개수 : 12807\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:39.514513Z",
     "start_time": "2023-09-13T16:46:38.735198Z"
    }
   },
   "id": "ee45d3d0271b5869"
  },
  {
   "cell_type": "markdown",
   "source": [
    "훈련 데이터와 테스트 데이터 모두 일정량의 샘플들이 제거된 것을 확인할 수 있어요. 이제 거의 다 왔어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f115d1f22231ff4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 패딩하기\n",
    "\n",
    "텍스트 시퀀스를 정수 시퀀스로 변환했다면, 이제 서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰주는 패딩 작업을 해주어야 해야 해요. 아까 정해두었던 최대 길이로 패딩 해 줄 거에요. 최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춰줄게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa316835dc0eaa1b"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=summary_max_len, padding='post')\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:46:47.463019Z",
     "start_time": "2023-09-13T16:46:47.160817Z"
    }
   },
   "id": "9d3175a0cb3dc960"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 학습에 필요한 데이터 전처리가 모두 끝났어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f832f587eb063577"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-8. 모델 설계하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2baa9144c4c4118"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제는 모델을 설계할 시간이에요. 우선 함수형 API를 이용해서 인코더를 설계해 볼게요.\n",
    "\n",
    "Q.인코더 LSTM 1을 참고해서 나머지 인코더의 LSTM 2, LSTM 3의 코드를 완성하세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaaf43dad3171b3a"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "# encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True ,dropout = 0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:59:46.307377Z",
     "start_time": "2023-09-13T16:59:45.832905Z"
    }
   },
   "id": "6b13d57610ed0212"
  },
  {
   "cell_type": "markdown",
   "source": [
    "임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의했어요. hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터에요. 이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수라고 이해하면 돼요. 다른 신경망과 마찬가지로, 무조건 용량을 많이 준다고 해서 성능이 반드시 올라가는 것은 아니에요.\n",
    "\n",
    "인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높였어요. hidden state의 크기를 늘리는 것이 LSTM 층 1개의 용량을 늘린다면, 3개의 층을 사용하는 것은 모델의 용량을 늘린다고 볼 수 있죠. 3개의 층을 지나서 인코더로부터 나온 출력 벡터는 디코더로 보내줘야겠죠?\n",
    "\n",
    "또한 LSTM은 dropout 뿐 아니라 recurrent dropout까지 사용할 수 있어요. 일반적인 dropout은 레이어의 weight를 랜덤으로 생략하여 모델의 과적합(overfitting)을 해결해주는 방법이에요.\n",
    "\n",
    "반면 recurrent dropout은 dropout을 레이어가 아닌 time step마다 해주는 방식이에요. 즉 time step의 입력을 랜덤으로 생략해 주는 거죠. recurrent dropout은 일반적인 dropout와 같이 regularization을 해주는 효과가 있고, 과적합을 방지할 수 있다고 해요.\n",
    "\n",
    "아래 그림은 일반적인 dropout과, dropout과 recurrent dropout을 동시에 사용한 것을 시각적으로 표현한 것입니다. 색이 있는 화살표는 dropout을 나타낸 것이에요. (색이 다른 것은 다른 dropout mask를 사용했다는 표시인데, 지금은 그냥 넘어가셔도 됩니다.) 코드를 수정해서 LSTM에 dropout과 recurrent dropout을 모두 사용할 수 있습니다. 그렇게 되면 오른쪽 그림과 같은 형태가 되겠군요. 참고로 dropout과 recurrent dropout을 모두 사용한 것을 Variational Dropout이라고도 해요.\n",
    "\n",
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/seukeurinsyas_2021-10-28_17-19-50.max-800x600.png)\n",
    "\n",
    "[dropout(왼쪽)과 dropout + recurrent dropout(오른쪽)]\n",
    "https://arxiv.org/pdf/1512.05287.pdf\n",
    "\n",
    "참고로 recurrent dropout을 사용하면 아래와 같은 경고문이 뜹니다.\n",
    "\n",
    "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
    "\n",
    "recurrent dropout을 사용할 시 cuDNN을 사용할 수 없어서 recurrent dropout을 사용하지 않을 때보다 학습 시간이 오래 걸립니다.\n",
    "\n",
    "recurrent dropout에 대한 자세한 내용은 아래의 논문을 참고하세요.\n",
    "\n",
    "Recurrent Dropout without Memory Loss\n",
    "https://arxiv.org/pdf/1603.05118v2.pdf\n",
    "\n",
    "이제 디코더를 설계해볼게요!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "400f66991f99624"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "# decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:59:47.177092Z",
     "start_time": "2023-09-13T16:59:47.018923Z"
    }
   },
   "id": "b07c83ccd3155abb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일해요. 하지만 LSTM의 입력을 정의할 때, initial_state의 인자값으로 인코더의 hidden state와 cell state의 값을 넣어줘야 해요.\n",
    "\n",
    "디코더의 출력층을 설계해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "807f29b2e82a19fd"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 50, 128)              1024000   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, 50, 256),            394240    ['embedding_1[0][0]']         \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(None, 50, 256),            525312    ['lstm_3[0][0]']              \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, None, 128)            256000    ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               [(None, 50, 256),            525312    ['lstm_4[0][0]']              \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               [(None, None, 256),          394240    ['embedding_2[0][0]',         \n",
      "                              (None, 256),                           'lstm_5[0][1]',              \n",
      "                              (None, 256)]                           'lstm_5[0][2]']              \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 2000)           514000    ['lstm_6[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3633104 (13.86 MB)\n",
      "Trainable params: 3633104 (13.86 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:59:48.946153Z",
     "start_time": "2023-09-13T16:59:48.847569Z"
    }
   },
   "id": "ee1badf1b404fb4f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야 해요. 그렇기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용하고 있어요.\n",
    "\n",
    "지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq에요. 그런데 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이 있어요! 바로 어텐션 메커니즘이에요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db76cea45ff2487f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 어텐션 메커니즘\n",
    "어텐션 메커니즘을 수행하는 어텐션 함수를 설계하는 것은 또 다른 새로운 신경망을 설계해야 한다는 뜻이에요. 어텐션 함수를 설계해보는 것은 다음 기회로 미루기로 하고, 여기서는 TensorFlow에 이미 구현된 어텐션 함수를 가져와서 디코더의 출력층에 어떤 방식으로 결합하는지 배워볼게요. 참고로 여기서 사용하는 어텐션 함수는 Bahdanau 스타일의 어텐션입니다. 이 어텐션에 대한 자세한 설명은 텐서플로우 홈페이지를 참고하세요.\n",
    "\n",
    "아래와 같이 어텐션 층을 만들고, 위에서 설계한 디코더의 출력층을 수정해 봅시다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe25d84ead6b3394"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 50)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 50, 128)              1024000   ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(None, 50, 256),            394240    ['embedding_1[0][0]']         \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(None, 50, 256),            525312    ['lstm_3[0][0]']              \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, None, 128)            256000    ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               [(None, 50, 256),            525312    ['lstm_4[0][0]']              \n",
      "                              (None, 256),                                                        \n",
      "                              (None, 256)]                                                        \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               [(None, None, 256),          394240    ['embedding_2[0][0]',         \n",
      "                              (None, 256),                           'lstm_5[0][1]',              \n",
      "                              (None, 256)]                           'lstm_5[0][2]']              \n",
      "                                                                                                  \n",
      " attention_layer (AdditiveA  (None, None, 256)            256       ['lstm_6[0][0]',              \n",
      " ttention)                                                           'lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " concat_layer (Concatenate)  (None, None, 512)            0         ['lstm_6[0][0]',              \n",
      "                                                                     'attention_layer[0][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 2000)           1026000   ['concat_layer[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4145360 (15.81 MB)\n",
      "Trainable params: 4145360 (15.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T16:59:51.342774Z",
     "start_time": "2023-09-13T16:59:51.221368Z"
    }
   },
   "id": "5f3287a18f0c6225"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-9. 모델 훈련하기\n",
    "\n",
    "설계한 모델을 가지고 훈련을 진행해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e962c0dec34d9770"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 01:59:56.983304: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"101\" frequency: 2903 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 16777216 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n",
      "2023-09-14 01:59:58.226580: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 104857600 exceeds 10% of free system memory.\n",
      "2023-09-14 01:59:58.269475: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 104857600 exceeds 10% of free system memory.\n",
      "2023-09-14 01:59:58.305032: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 16384000 exceeds 10% of free system memory.\n",
      "2023-09-14 01:59:58.347494: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 104857600 exceeds 10% of free system memory.\n",
      "2023-09-14 01:59:58.356217: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 104857600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - ETA: 0s - loss: 2.9035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 02:02:20.381410: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"101\" frequency: 2903 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 16777216 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 161s 778ms/step - loss: 2.9035 - val_loss: 2.5469\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 157s 782ms/step - loss: 2.5472 - val_loss: 2.4775\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - ETA: 0s - loss: 2.4695"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrmsprop\u001B[39m\u001B[38;5;124m'\u001B[39m, loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      2\u001B[0m es \u001B[38;5;241m=\u001B[39m EarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mencoder_input_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_input_train\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecoder_target_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m          \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mencoder_input_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_input_test\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecoder_target_test\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m\\\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m          \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mes\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/keras/src/engine/training.py:1791\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_eval_data_handler\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_eval_data_handler \u001B[38;5;241m=\u001B[39m data_adapter\u001B[38;5;241m.\u001B[39mget_data_handler(\n\u001B[1;32m   1777\u001B[0m         x\u001B[38;5;241m=\u001B[39mval_x,\n\u001B[1;32m   1778\u001B[0m         y\u001B[38;5;241m=\u001B[39mval_y,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1789\u001B[0m         pss_evaluation_shards\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pss_evaluation_shards,\n\u001B[1;32m   1790\u001B[0m     )\n\u001B[0;32m-> 1791\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_x\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1793\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_y\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1794\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_batch_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1796\u001B[0m \u001B[43m    \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_queue_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_queue_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1799\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworkers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mworkers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1800\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_multiprocessing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_multiprocessing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1801\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1802\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_use_cached_eval_dataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1803\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1804\u001B[0m val_logs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   1805\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m name: val \u001B[38;5;28;01mfor\u001B[39;00m name, val \u001B[38;5;129;01min\u001B[39;00m val_logs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m   1806\u001B[0m }\n\u001B[1;32m   1807\u001B[0m epoch_logs\u001B[38;5;241m.\u001B[39mupdate(val_logs)\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/keras/src/engine/training.py:2200\u001B[0m, in \u001B[0;36mModel.evaluate\u001B[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001B[0m\n\u001B[1;32m   2196\u001B[0m             \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   2197\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m\"\u001B[39m, step_num\u001B[38;5;241m=\u001B[39mstep, _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   2198\u001B[0m             ):\n\u001B[1;32m   2199\u001B[0m                 callbacks\u001B[38;5;241m.\u001B[39mon_test_batch_begin(step)\n\u001B[0;32m-> 2200\u001B[0m                 logs \u001B[38;5;241m=\u001B[39m \u001B[43mtest_function_runner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2201\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2202\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mdata_handler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2203\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2204\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pss_evaluation_shards\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2205\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2207\u001B[0m logs \u001B[38;5;241m=\u001B[39m tf_utils\u001B[38;5;241m.\u001B[39msync_to_numpy_or_python_type(logs)\n\u001B[1;32m   2208\u001B[0m \u001B[38;5;66;03m# Override with model metrics instead of last step logs\u001B[39;00m\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/keras/src/engine/training.py:4000\u001B[0m, in \u001B[0;36m_TestFunction.run_step\u001B[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001B[0m\n\u001B[1;32m   3999\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_step\u001B[39m(\u001B[38;5;28mself\u001B[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001B[0;32m-> 4000\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_or_iterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4001\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   4002\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    822\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    824\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 825\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    827\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    828\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:864\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    861\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    862\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    863\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 864\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    867\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    146\u001B[0m   (concrete_function,\n\u001B[1;32m    147\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m--> 148\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs)\u001B[0m\n\u001B[1;32m   1345\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1346\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1347\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1348\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1349\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1350\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1351\u001B[0m     args,\n\u001B[1;32m   1352\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1353\u001B[0m     executing_eagerly)\n\u001B[1;32m   1354\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    194\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    195\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 196\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    197\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    201\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    202\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mlist\u001B[39m(args))\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1455\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1456\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1457\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1462\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1463\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1465\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1466\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1467\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1471\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1472\u001B[0m   )\n",
      "File \u001B[0;32m~/.virtualenvs/exploration/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T17:07:43.994308Z",
     "start_time": "2023-09-13T16:59:53.638410Z"
    }
   },
   "id": "63254146a1f2a1db"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8e3ec274f519bb12"
  },
  {
   "cell_type": "markdown",
   "source": [
    "'조기 종료'를 뜻하는 EarlyStopping은 특정 조건이 충족되면 훈련을 멈추는 역할을 해요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54bb9c7685a309f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a084f8e5f07a3787"
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 코드에서는 val_loss(검증 데이터의 손실)을 관찰하다가, 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정돼 있어요. EarlyStopping이 작동한다면 epochs가 아무리 크게 설정되어 있어도 모델 훈련을 최적점에서 멈출 수 있겠네요.\n",
    "\n",
    "EarlyStopping에 대한 자세한 내용은 아래 링크를 참고하세요! 자주 쓰이는 도구이니 자세히 알아두면 매우 도움이 될 거예요!!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a88d91aa11bb2c9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Early Stopping\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4489c1c00a3bdfa0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. Early Stopping을 사용할 경우 조심해야 하는 경우가 있는데, 어떤 경우일까요?\n",
    "\n",
    "LMS \n",
    "\n",
    "patience가 0이 아닌 경우에는 훈련이 종료되었을 때 성능이 최고인 상황이 아닐 수 있습니다. 예를들어 patience가 3인 경우, 15 epoch에서 loss가 감소하다가 16 epoch부터 loss가 증가한다면 18 epoch 때 모델을 저장하고 학습을 종료합니다. 그래서 학습 중에 모델을 저장하는 callback 함수를 같이 사용한다.\n",
    "\n",
    "GPT\n",
    "\n",
    "Early Stopping은 모델 훈련 중에 일찍 멈추는 기법으로, 검증 데이터의 성능이 개선되지 않거나 악화될 때 훈련을 조기에 종료시키는 것을 의미합니다. 이 기법은 과적합(overfitting)을 방지하고 일반화 성능을 향상시킬 수 있습니다. 그러나 Early Stopping을 사용할 때 주의해야 할 몇 가지 경우가 있습니다:\n",
    "\n",
    "1. 너무 일찍 멈추는 경우: Early Stopping은 모델이 더 이상 개선되지 않거나 과적합이 시작될 때 훈련을 종료합니다. 그러나 때로는 모델이 아직 최적의 성능에 도달하지 않았음에도 불구하고, 너무 일찍 훈련이 종료될 수 있습니다. 따라서 적절한 patience(인내) 값과 함께 사용하여 충분한 시간 동안 성능 개선 여부를 확인하는 것이 중요합니다.\n",
    "\n",
    "2. 잘못된 검증 데이터 선택: Early Stopping은 보통 검증 데이터를 사용하여 모델의 성능을 평가하고 결정합니다. 검증 데이터가 대표성이 없거나 불균형한 경우, Early Stopping에서 얻는 결과가 실제 테스트 데이터에서의 성능과 차이가 날 수 있습니다. 따라서 검증 데이터셋은 실제 환경과 유사하게 구성되어야 합니다.\n",
    "\n",
    "3. 지역 최소값 문제: 모델 학습 과정에서 경사 하강법 등의 최적화 알고리즘이 지역 최소값(local minimum)에 갇힐 수 있습니다. 이런 경우, 약간의 오차 감소로 인해 큰 개선 없음으로 인해 조기 종료되어 정말로 좋은 전역 최소값(global minimum)에 도달하지 못할 수도 있습니다.\n",
    "\n",
    "4. 학습률 조정 문제: Early Stopping 시점에서 학습률(learning rate)을 적절하게 조정하지 않으면, 최적화 과정에서 많은 에포크(epoch)를 거치면서 정확도가 높아집니다만, 조기 종료 후 다시 에포크를 진행할 때 학습률 설정 문제로 인해 오히려 정확도가 낮아질 수 있습니다.\n",
    "\n",
    "5. 다른 하이퍼파라미터와 상호작용 문제: Early Stopping 기법은 다른 하이퍼파라미터와 상호작용할 수 있는데, 예를 들어 네트워크 구조 변경 등 다른 변화와 함께 사용됩니다.\n",
    "   \n",
    "따라서 Early Stopping을 적용할 때에는 위와 같은 주의사항들을 염두에 두고 설정 및 관리해야 합니다.\n",
    "실험 및 경험이 필요한 부분입니다.\n",
    "모델과 데이터셋에 따라 적절한 파라미터 값을 찾아내기 위해서 반복 실험이 필요할 수 있으며,\n",
    "검증 데이터셋 선택 및 관리 등 실전 상황과 연관된 요소들도 중요합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5abadd99ddbeedb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정을 시각화 해봐요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42c4c5755ad4a009"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:11:39.356024Z",
     "start_time": "2023-09-13T15:11:39.238495Z"
    }
   },
   "id": "8ede2314b7c2ac3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-10. 인퍼런스 모델 구현하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab3a9b002545401c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "테스트 단계에서는 정수 인덱스 행렬로 존재하던 텍스트 데이터를 실제 데이터로 복원해야 하므로, 필요한 3개의 사전을 아래와 같이 미리 준비해 둡니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fbc772ecdc034c0f"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:17:53.300686Z",
     "start_time": "2023-09-13T15:17:53.279588Z"
    }
   },
   "id": "861264adf4b6c900"
  },
  {
   "cell_type": "markdown",
   "source": [
    "seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 한다는 것, 알고 계시나요?\n",
    "\n",
    "훈련 단계에서는 디코더의 입력부에 정답이 되는 문장 전체를 한꺼번에 넣고 디코더의 출력과 한 번에 비교할 수 있으므로, 인코더와 디코더를 엮은 통짜 모델 하나만 준비했습니다.\n",
    "\n",
    "그러나 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 합니다. 이때는 인코더 모델과 디코더 모델을 분리해서 설계합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea9288d14489daaf"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:18:21.139338Z",
     "start_time": "2023-09-13T15:18:20.986470Z"
    }
   },
   "id": "b6a3fd95e281c87"
  },
  {
   "cell_type": "markdown",
   "source": [
    "어텐션 메커니즘을 사용하는 출력층을 설계해 주세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb50f9f5ad6a8120"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:18:40.981739Z",
     "start_time": "2023-09-13T15:18:40.904971Z"
    }
   },
   "id": "cc0df7f68c72ac19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "인퍼런스 단계에서 단어 시퀀스를 완성하는 함수를 만들어주세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c05849e8cf048591"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:18:58.806365Z",
     "start_time": "2023-09-13T15:18:58.763743Z"
    }
   },
   "id": "76d1a8d42fc3a949"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Q. 정답 문장이 없는 추론(inference) 단계에서는 왜 모델 설계를 별도로 해주어야 하나요?\n",
    "\n",
    "LMS\n",
    "\n",
    "생성해야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문입니다.\n",
    "\n",
    "GPT\n",
    "\n",
    "정답 문장이 없는 추론(inference) 단계에서 모델 설계를 별도로 해주어야 하는 이유는 다음과 같습니다:\n",
    "\n",
    "1. 입력 데이터 형식: 훈련 단계와 추론 단계에서 입력 데이터의 형식이 다를 수 있습니다. 예를 들어, 훈련 단계에서는 입력 시퀀스와 해당 시퀀스의 정답 레이블을 함께 사용하여 모델을 학습시키지만, 추론 단계에서는 정답 레이블 없이 입력 시퀀스에 대한 예측을 수행합니다. 따라서 모델 설계를 별도로 해주어야 훈련과 추론 과정 각각에 맞게 데이터 처리 및 모델 구조를 조정할 수 있습니다.\n",
    "\n",
    "2. Dropout 및 Batch Normalization 등의 적용: 훈련 과정에서 일반적으로 사용되는 Dropout, Batch Normalization 등과 같은 기법들은 모델을 더 강건하게 만들기 위해 사용됩니다. 그러나 이러한 기법들은 훈련 중에만 적용되고, 추론 단계에서는 비활성화되어야 합니다. 따라서 추론 과정에서도 올바른 결과를 얻기 위해 이러한 기법들을 관리하기 위한 별도의 모델 설계가 필요합니다.\n",
    "\n",
    "3. 파라미터 저장 및 재사용: 일반적으로 훈련된 모델은 파라미터(가중치) 값을 저장하고 나중에 재사용할 수 있습니다. 추론 과정에서 이러한 저장된 파라미터 값을 로드하여 사용할 수 있으며, 이때 별도의 모델 설계가 필요합니다.\n",
    "\n",
    "4. 하드웨어 및 배포 환경 호환성: 훈련과 추론 단계에서 사용되는 하드웨어 리소스나 배포 환경(예: CPU 또는 GPU)이 다를 수 있습니다. 따라서 각각의 환경에 맞게 최적화된 모델 설계가 필요합니다.\n",
    "\n",
    "따라서 정답 문장이 없는 추론 단계에서도 올바른 결과를 얻기 위해서는 해당 상황에 맞춰서 별도로 모델을 설계하고 관리해야 합니다.\n",
    "추론 시점에서 필요한 작업(예측, 분류 등)에 적합하고 최적화된 구조와 동작 방식을 가진 병렬적인 인공지능 아키텍처나 코드 작성 등으로 구현해야 합니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8e04f80fc3c1b9d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-11. 모델 테스트하기\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "864145937ec4cccd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "테스트 단계에서는 정수 시퀀스를 텍스트 시퀀스로 변환하여 결과를 확인하는 것이 편하겠죠. 주어진 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수를 만들어볼게요. 함수를 만들 때, Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만들 거예요.\n",
    "\n",
    "Q. seq2text 함수처럼 요약문의 정수 시퀀스를 텍스트로 변환하는 seq2summary 함수 코드를 작성하세요.\n",
    "(힌트 : 요약문에는 sostoken과 eostoken을 고려해야 함)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8454cdee4c238580"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "# seq2text 함수처럼 요약문의 정수 시퀀스를 텍스트로 변환하는 seq2summary 함수 코드를 작성하세요.\n",
    "# (힌트 : 요약문에는 sostoken과 eostoken을 고려해야 함)\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp\n",
    "\n",
    "print('=3')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:32:04.675396Z",
     "start_time": "2023-09-13T15:32:04.645673Z"
    }
   },
   "id": "954921ce8f59a8d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "테스트 데이터 약 50개의 샘플에 대해서 실제 요약과 예측된 요약을 비교해보세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3cc2b82c04479af8"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : actual package received shown product picture seriously reduces value beware black friday monday savings company shame amazon kicking holiday season bait switch happy amazon time missed one amazon refunded large enough portion purchase price satisfy kudos response \n",
      "실제 요약 : misleading item picture by amazon or the vendor \n",
      "1/1 [==============================] - 1s 775ms/step\n",
      "1/1 [==============================] - 0s 242ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : purchased sons mos years eat snack dinner knew getting fruit serving tried gave pretty good definitely distinct banana taste fine us like containers think plum organics happy baby comparable products less expensive ella kitchen products would definitely buy though \n",
      "실제 요약 : pretty good \n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 00:32:23.675331: W tensorflow/core/grappler/costs/op_level_cost_estimator.cc:693] Error in PredictCost() for the op: op: \"Softmax\" attr { key: \"T\" value { type: DT_FLOAT } } inputs { dtype: DT_FLOAT shape { unknown_rank: true } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"101\" frequency: 2903 num_cores: 16 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 16777216 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { unknown_rank: true } }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : good know got bad batch tastes bad try risk \n",
      "실제 요약 : yuck \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  horrible\n",
      "\n",
      "\n",
      "원문 : tea tasty love night little soy milk splenda would recommend people trying healthy green tea \n",
      "실제 요약 : yummy \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : dogs love treats give head approval give best price found always order amazon use training treats since small flavorful fattening dogs \n",
      "실제 요약 : my dogs love these treats \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great treats\n",
      "\n",
      "\n",
      "원문 : cost san francisco bay cups lowest able find anywhere good coffee deal hard beat \n",
      "실제 요약 : good coffee great price \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : person say dog treat yellow lab loves treats like organic product also like newmans charity important recommend treats \n",
      "실제 요약 : good dog treat \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : candies filled pecans cashews caramel chocolate pecans cheap ingredients cashews caramel expensive looking real cashew turtles lots gooey caramel guess assumed could tell difference pecans cashews product label real exercise downright product may may contain following ingredients could put sticker anything one word cashews \n",
      "실제 요약 : the old bait and switch not cashews \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  not the same taste\n",
      "\n",
      "\n",
      "원문 : absolutely love dark chocolate tried many different varieties one favorites due complex flavor great dense smooth texture also pack economical way purchase \n",
      "실제 요약 : excellent texture flavor \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great for\n",
      "\n",
      "\n",
      "원문 : family company continues tremendous local appreciate company shown us years back donated school recently provided staff one cup coffee maker samples wonderful keurig coffees favorite french roast strong flavor smooth finish please support company purchasing coffee \n",
      "실제 요약 : great great coffee \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : tea crisp clean fresh taste lemon ginger flavors get one enjoy every cup \n",
      "실제 요약 : great green tea \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  good tea\n",
      "\n",
      "\n",
      "원문 : like crackers last two times ordered smashed \n",
      "실제 요약 : condition \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : pregnant got cold tea help lot kind tea family winter cold season \n",
      "실제 요약 : great tea for my cold \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : bought great nephew absolutely loves mom particular gives got getting would recommend moms \n",
      "실제 요약 : good buy \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : ordered millet flour bulk twice order third time none expired fine use lot never problem \n",
      "실제 요약 : fine flour \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : researching pet food ratings quality ingredients settled cat food two adult cats food great ratings quality ingredients reasonably priced comparison many higher end pet foods cats eating several years still seem enjoy coats soft shiny amount food eat less quality food \n",
      "실제 요약 : great value for quality cat food \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  my cats love it\n",
      "\n",
      "\n",
      "원문 : dog loves treats buying target found amazon bulk much lower per pack price got father dog hooked buys amazon \n",
      "실제 요약 : dogswell happy hips treats \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : like product much signed monthly shipment think says lot healthy tasty time \n",
      "실제 요약 : great gluten free snack bars \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  good\n",
      "\n",
      "\n",
      "원문 : used get years back amazing bought times taste different like something taste really dry kinda plain feeling recipe change something fact flavor ones available huge boxes sure wanting save money ingredients selling bulk buying \n",
      "실제 요약 : they changed the recipe \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  good stuff\n",
      "\n",
      "\n",
      "원문 : bought throw sons lunch box really enjoys bought yellow red likes yellow ones best reason give stars price clearly paying ease product \n",
      "실제 요약 : quick easy and gone in days \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  good food\n",
      "\n",
      "\n",
      "원문 : beans well packaged clean minimal debris typically roast scoops days worth outside bbq grill side burner whirley pop full city grind use morning grinder fine consistency finally make espresso classic using non froth milk end cappucino heaven starbuck eat heart \n",
      "실제 요약 : going for the shot \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great taste\n",
      "\n",
      "\n",
      "원문 : golden two years old lbs anything get treats every night far best treats found \n",
      "실제 요약 : the best treats for our dog \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great treat\n",
      "\n",
      "\n",
      "원문 : disappointing coffee weak set brew medium get flavor large watered would find something different buying \n",
      "실제 요약 : not worth the money weak \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : nature path honey corn flakes really great tasting healthy gluten free highly recommend cereal \n",
      "실제 요약 : this cereal is really great \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  great for breakfast\n",
      "\n",
      "\n",
      "원문 : tried flavors least original teriyaki multiple times first batch original teriyaki great nd rd batches flavored pepper peppery hickory strong salty consistent going waste money product \n",
      "실제 요약 : inconsistent \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  too salty\n",
      "\n",
      "\n",
      "원문 : remember candy little girl saw amazon arrived quite fast good yrs ago \n",
      "실제 요약 : so good \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  haribo gummi candy\n",
      "\n",
      "\n",
      "원문 : guess taco sauce flavor taco would okay reaching bottle would top choice taco sauce tastes much like salad dressing spicier makes think might liked better presented salad dressing instead taco sauce love hate would buy dining pleasure \n",
      "실제 요약 : it tastes like spicy dressing \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  not hot sauce\n",
      "\n",
      "\n",
      "원문 : tried product little research online product lived good reviews like protein shakes best cold usually make drink exercising classes starting back plan switching mornings since class downside product trying find perfect amount oz water get shake taste perfect nonetheless still good \n",
      "실제 요약 : best so far \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  great stuff\n",
      "\n",
      "\n",
      "원문 : chews almost like puppy loves keep occupied minutes good teeth \n",
      "실제 요약 : my puppy loves these \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  my dogs love these\n",
      "\n",
      "\n",
      "원문 : fancy box great price always purchased large amount splenda wholesale club buy amazon even better price free shipping member fee \n",
      "실제 요약 : just what wanted \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great deal\n",
      "\n",
      "\n",
      "원문 : make fresh prepared mustard using frontier mustard seed frontier mustard consistent quality flavor proud use product gladly award stars \n",
      "실제 요약 : great price great mustard \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  great popcorn\n",
      "\n",
      "\n",
      "원문 : bought whole pack liked izze grapefruit sparkling juice great disappointment first taste taste like natural pomegranate \n",
      "실제 요약 : tastes like cough syrup \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : yes coffee good raise price without letting anyone know expect price account price goes without warning notice cool \n",
      "실제 요약 : price without \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : variety pack delicious love vegan gluten free organic flavor box one yummy \n",
      "실제 요약 : delicious \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great gluten free cookies\n",
      "\n",
      "\n",
      "원문 : like reviews package come fancy blue box instead comes generic cardboard box however things amazon still significantly cheaper walmart target places cant complain luckily get busted cups box going break room work probably order amount cups get cost cannot beaten \n",
      "실제 요약 : great but not exactly as pictured \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  do not buy again\n",
      "\n",
      "\n",
      "원문 : gift son eats whole raw skeptical product would hot enough well extremely pleased even try \n",
      "실제 요약 : hot hot hot \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great gift\n",
      "\n",
      "\n",
      "원문 : purchased taste thai red green yellow curry pastes well pad thai sauce beyond excellent worth every cent bucket sizes incredibly economical \n",
      "실제 요약 : our fave curry paste \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great for the price\n",
      "\n",
      "\n",
      "원문 : chihuahua take try eat big little mouth treats hard break pieces interested enough chew bigger pieces though say dog never dog biscuit type could part reason enjoy good quality product made great ingredients every dog going like obviously \n",
      "실제 요약 : too big for small \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : great way limit snacks calories tastes good well helps cravings higher calorie treats \n",
      "실제 요약 : handy portion control \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : tea premium quality stated box wish amazon carrying larger packages box tea bags \n",
      "실제 요약 : stash tea \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  tea\n",
      "\n",
      "\n",
      "원문 : feel milk supply increased within hours loose bowel movement first day taking fenugreek seed pills help constipation nursing daughter almost hour first month necessary milk supply help pill month old without supplement bottle washing save time save money lose weight without diet exercise great \n",
      "실제 요약 : worth try \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great for hair\n",
      "\n",
      "\n",
      "원문 : dogs think chicken zuke minis really tasty problem treats tiny lb german shepherd swallows dust excellent smaller dog wish slightly larger bigger kids \n",
      "실제 요약 : dogs like them \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  my dogs love these\n",
      "\n",
      "\n",
      "원문 : blue plate mayonnaise tastes better hellman cannot get blue plate stores northeast mail ordered worries though cheaper gotten number jars hellman locally go figure \n",
      "실제 요약 : better and cheaper than \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  good but\n",
      "\n",
      "\n",
      "원문 : feel compelled buy get whole foods waste money buying pack buyer beware cannot return many food items texture like must dehydrated tofu hiking camping trips make buy tofu sealed boxes flip side love many eden products waste money \n",
      "실제 요약 : this is really bad like when \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  stale\n",
      "\n",
      "\n",
      "원문 : bought tea health benefits although biggest fan tea knew tea extremely overbearing hard drink team smelled like perfume well tasted like left mouth smelling like drank bottle perfume pleasant usually handle things taste bad exception get strong taste however sure fine \n",
      "실제 요약 : tea tastes like \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "예측 요약 :  not what expected\n",
      "\n",
      "\n",
      "원문 : coffee okay certainly good green mountain breakfast blend taste good \n",
      "실제 요약 : okay but not great \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : unlike gluten free granola granola greasy crunchy flavorful love granola subscribed flavor amazon cheaper grocery store love variety nuts fruits great yogurt topper cereal \n",
      "실제 요약 : crunchy gluten free goodness \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  yummy\n",
      "\n",
      "\n",
      "원문 : absolutely best tasting coffee world bold taste along rich flavor folks come house taste french market coffee get hooked convert dedicated french market coffee drinkers \n",
      "실제 요약 : french market coffee best coffee in the world \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : actually bought oz bags daughter coffee deal junkie could pass offer us \n",
      "실제 요약 : just the last of my cafe \n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : hazelnut decaf absolutely delicious mellow smooth bit bitter one choosing daily basic coffee \n",
      "실제 요약 : my favorite \n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "예측 요약 :  great coffee\n"
     ]
    }
   ],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:32:32.970192Z",
     "start_time": "2023-09-13T15:32:22.765100Z"
    }
   },
   "id": "b814110104974bfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "많은 결과가 출력이 되는데, 기존의 요약과는 다른 요약을 출력하면서도 원문의 내용을 담고 있는 의미 있는 요약들이 보이네요. 심지어 일부 요약의 경우에는 원문에 없던 단어를 사용해서 요약을 하기도 하고 있어요. 워드 임베딩과 RNN의 콜라보로 이뤄낸 신기한 성과네요!\n",
    "\n",
    "물론 슬프게도 그다지 좋지 않은 요약의 예도 꽤나 보이기도 하네요. 성능을 개선하기 위해서는 seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법도 있고, 빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), 또는 인코더 - 디코더 자체의 구조를 새로이 변경한 하는 트랜스포머(Transformer)와 같은 여러 개선 방안들이 존재합니다. 이런 방안들에 대해서도 향후 살펴보게 될 것입니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c532601a2b4313"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3-12. 추출적 요약 해보기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "625fc6849f124445"
  },
  {
   "cell_type": "markdown",
   "source": [
    "앞서 seq2seq를 통해서 추상적 요약을 진행해봤어요. 그런데 텍스트 요약에는 추상적 요약 외에도 이미 본문에 존재하는 단어구, 문장을 뽑아서 요약으로 삼는 추출적 요약 방법도 있었죠.\n",
    "\n",
    "Q. 우리가 앞에서 seq2seq 모델을 사용하여 추상적 요약을 했습니다. 그렇다면 추출적 요약은 무엇일까요?\n",
    "\n",
    "추출적 요약은 원문에서 중요한 핵심 문장 또는 단어를 뽑아 구성된 요약문을 만드는 방식입니다. 그래서 생성된 문장이나 단어는 원문에 포함되어 있기 때문에, 단점으로 언어 표현 능력이 제한되어 생성된 문장이 매끄럽지 않을 수 있습니다. 대표적인 알고리즘으로는 TextRank가 있습니다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95e1dc7218fa6393"
  },
  {
   "cell_type": "markdown",
   "source": [
    "패키지 Summa에서는 추출적 요약을 위한 모듈인 summarize를 제공하고 있어 아주 간단하게 실습을 해볼 수 있어요. 영화 매트릭스 시놉시스를 요약해보면서 summarize 사용법을 익혀볼까요?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3d43984f5da68a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 패키지 설치\n",
    "\n",
    "클라우드의 경우 이미 summa 가 설치돼있습니다. 확인해보고 싶으시면 아래 명령어를 Cloud Shell에서 실행해보세요!\n",
    "\n",
    "$ pip list | grep summa"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d380a32112ba240a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 데이터 다운로드하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6142affc540c11b"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:47:55.715853Z",
     "start_time": "2023-09-13T15:47:55.650474Z"
    }
   },
   "id": "1a70028a611025a5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "매트릭스 시놉시스를 다운로드 해주세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b6dd8974d15c5ed"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:48:10.591388Z",
     "start_time": "2023-09-13T15:48:10.076266Z"
    }
   },
   "id": "e84e9a8a4e449c6f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 text에는 매트릭스 시놉시스가 문자열로 저장돼 있어요. 출력 결과가 아주 길기 때문에 일부만 출력해보고, 잘 저장이 되었는지 확인해볼게요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbddac043793dd22"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:48:38.159419Z",
     "start_time": "2023-09-13T15:48:38.127763Z"
    }
   },
   "id": "1c3c921df42e4fa7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### summarize 사용하기\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d66e402379dff47c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Summa의 summarize()의 인자로 사용되는 값들에 대해서 알아볼게요.\n",
    "\n",
    "text (str) : 요약할 테스트.\n",
    "\n",
    "ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값\n",
    "\n",
    "words (int or None, optional) – 출력에 포함할 단어 수.\n",
    "\n",
    "만약, ratio와 함께 두 파라미터가 모두 제공되는 경우 ratio는 무시한다.\n",
    "\n",
    "split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환\n",
    "\n",
    "Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행해요. 그렇기 때문에 문장 구분이 되어있지 않은 원문을 바로 입력으로 넣을 수 있어요. 비율을 적게 주어서 요약문으로 선택되는 문장의 개수를 줄여볼게요. 원문의 0.005%만을 출력하도록 설정했어요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a92f515436569598"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:49:24.854549Z",
     "start_time": "2023-09-13T15:49:23.144590Z"
    }
   },
   "id": "cd4330549697a345"
  },
  {
   "cell_type": "markdown",
   "source": [
    "만약 리스트로 출력 결과를 받고 싶다면 split 인자의 값을 True로 하면 돼요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "135955fc7761ab7e"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:49:45.388580Z",
     "start_time": "2023-09-13T15:49:44.557490Z"
    }
   },
   "id": "8565029bc6f7f565"
  },
  {
   "cell_type": "markdown",
   "source": [
    "단어의 수로 요약문의 크기를 조절할 수도 있어요. 단어를 50개만 선택하도록 해보세요."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c48cc8409f879ae3"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-13T15:50:03.477286Z",
     "start_time": "2023-09-13T15:50:02.766940Z"
    }
   },
   "id": "8af1cc56bc4c21db"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "42f922153d87208d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "16953f3157e4eb4d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a1868dd259a00cfa"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a9c8b770c0b20de1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
